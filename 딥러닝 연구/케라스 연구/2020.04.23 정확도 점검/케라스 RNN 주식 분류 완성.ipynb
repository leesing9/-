{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import FinanceDataReader as fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pandf = fdr.DataReader(\"KS11\",\"2010-01-01\",\"2020-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특성 추가 ------------------------------------------\n",
    "    #이동평균선\n",
    "def get_MA(df):\n",
    "    MA_26=df[\"Close\"].rolling(26).mean()\n",
    "    MA_52=df[\"Close\"].rolling(52).mean()\n",
    "    df=df.assign(MA_26=MA_26,MA_52=MA_52).dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "    #스토캐스틱\n",
    "def get_stochastic(df, n=15, m=5, t=3):\n",
    "    # n일중 최고가\n",
    "    ndays_high = df.High.rolling(window=n, min_periods=1).max()\n",
    "    # n일중 최저가\n",
    "    ndays_low = df.Low.rolling(window=n, min_periods=1).min()\n",
    " \n",
    "    # Fast%K 계산\n",
    "    kdj_k = ((df.Close - ndays_low) / (ndays_high - ndays_low))*100\n",
    "    # Fast%D (=Slow%K) 계산\n",
    "    kdj_d = kdj_k.ewm(span=m).mean()\n",
    "    # Slow%D 계산\n",
    "    kdj_j = kdj_d.ewm(span=t).mean()\n",
    " \n",
    "    # dataframe에 컬럼 추가\n",
    "    df = df.assign(kdj_k=kdj_k, kdj_d=kdj_d, kdj_j=kdj_j).dropna()\n",
    "    \n",
    "    return df\n",
    "   \n",
    "    #시간\n",
    "def get_time(df):\n",
    "    time=np.linspace(0,10,len(df),endpoint=False).reshape(-1,1)\n",
    "    df=df.assign(time=time)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pandf\n",
    "df=get_time(df)\n",
    "df=get_stochastic(df)\n",
    "df=get_MA(df)\n",
    "# convert nparray\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# day 1, 20 / 값, 이동평균선\n",
    "MA_26=df[\"Close\"].rolling(21).mean()\n",
    "y_before=MA_26.dropna()\n",
    "\n",
    "dfA=df[20:] #값과 값 -> [:] 이평선 -> [20:]  <- [20: 0 XXXX]\n",
    "\n",
    "#y=np.where(np.array(dfA[\"Close\"].shift(-1).dropna())>np.array(y_before.shift(-1).dropna()),1,0) #값과 이평선 ( 1일 차 )\n",
    "#y=np.where(dfA[\"Change\"].shift(-1).dropna()>0,1,0) #값과 값 ( 1일 차 )\n",
    "y=np.where(np.array(dfA[\"Close\"].shift(-20).dropna())>np.array(y_before.shift(-20).dropna()),1,0) #값과 이평선( 20일 차 )\n",
    "#y=np.where(dfA[\"Change\"].shift(-20).dropna()>0,1,0) #값과 값 ( 20일 차 )\n",
    "\n",
    "df = dfA[:-20] # 1일차일시 [:-1] 20일차일시 [:-20]\n",
    "# normalization\n",
    "X=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1663, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split train, test\n",
    "train_size = int(len(X) * 0.7)\n",
    "y_train2=y[:train_size]\n",
    "y_test2=y[train_size:]\n",
    "X_train2 = X[:train_size]\n",
    "X_test2 = X[train_size:]\n",
    "X_train2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-940e6c7b20f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# reshape input to be [samples, time steps, features]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    290\u001b[0m            [5, 6]])\n\u001b[0;32m    291\u001b[0m     \"\"\"\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;31m# a downstream library like 'pandas'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[1;34m(self, result, context)\u001b[0m\n\u001b[0;32m   1997\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1998\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_axes_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_ORDERS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1999\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m     \u001b[1;31m# ideally we would define this to avoid the getattr checks, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;31m# by definition an array here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mprep_ndarray\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Must pass 2-d input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input"
     ]
    }
   ],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train2, (X_train2.shape[0], 1, X_train2.shape[1]))\n",
    "X_test = np.reshape(X_test2, (X_test2.shape[0], 1, X_test2.shape[1]))\n",
    "y_train=y_train2\n",
    "y_test=y_test2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1496 samples, validate on 167 samples\n",
      "Epoch 1/100\n",
      "1496/1496 [==============================] - 1s 391us/step - loss: 0.6886 - acc: 0.5541 - val_loss: 0.6621 - val_acc: 0.6407\n",
      "Epoch 2/100\n",
      "1496/1496 [==============================] - 0s 99us/step - loss: 0.6712 - acc: 0.5969 - val_loss: 0.6393 - val_acc: 0.6707\n",
      "Epoch 3/100\n",
      "1496/1496 [==============================] - 0s 98us/step - loss: 0.6543 - acc: 0.6263 - val_loss: 0.7260 - val_acc: 0.4072\n",
      "Epoch 4/100\n",
      "1496/1496 [==============================] - 0s 106us/step - loss: 0.6524 - acc: 0.6223 - val_loss: 0.7180 - val_acc: 0.4192\n",
      "Epoch 5/100\n",
      "1496/1496 [==============================] - 0s 97us/step - loss: 0.6460 - acc: 0.6344 - val_loss: 0.7026 - val_acc: 0.4491\n",
      "Epoch 6/100\n",
      "1496/1496 [==============================] - 0s 103us/step - loss: 0.6450 - acc: 0.6430 - val_loss: 0.6835 - val_acc: 0.5210\n",
      "Epoch 7/100\n",
      "1496/1496 [==============================] - 0s 103us/step - loss: 0.6446 - acc: 0.6497 - val_loss: 0.6406 - val_acc: 0.7006\n",
      "Epoch 8/100\n",
      "1496/1496 [==============================] - 0s 103us/step - loss: 0.6420 - acc: 0.6324 - val_loss: 0.6109 - val_acc: 0.7006\n",
      "Epoch 9/100\n",
      "1496/1496 [==============================] - 0s 98us/step - loss: 0.6472 - acc: 0.6297 - val_loss: 0.6254 - val_acc: 0.6946\n",
      "Epoch 10/100\n",
      "1496/1496 [==============================] - 0s 101us/step - loss: 0.6445 - acc: 0.6424 - val_loss: 0.6180 - val_acc: 0.6946\n",
      "Epoch 11/100\n",
      "1496/1496 [==============================] - 0s 99us/step - loss: 0.6501 - acc: 0.6430 - val_loss: 0.6712 - val_acc: 0.5808\n",
      "Epoch 12/100\n",
      "1496/1496 [==============================] - 0s 105us/step - loss: 0.6380 - acc: 0.6430 - val_loss: 0.6495 - val_acc: 0.6647\n",
      "Epoch 13/100\n",
      "1496/1496 [==============================] - 0s 102us/step - loss: 0.6392 - acc: 0.6484 - val_loss: 0.6926 - val_acc: 0.4910\n",
      "Epoch 14/100\n",
      "1496/1496 [==============================] - 0s 101us/step - loss: 0.6368 - acc: 0.6564 - val_loss: 0.6152 - val_acc: 0.6946\n",
      "Epoch 15/100\n",
      "1496/1496 [==============================] - 0s 114us/step - loss: 0.6383 - acc: 0.6384 - val_loss: 0.6290 - val_acc: 0.7665\n",
      "Epoch 16/100\n",
      "1496/1496 [==============================] - 0s 99us/step - loss: 0.6337 - acc: 0.6457 - val_loss: 0.6944 - val_acc: 0.4850\n",
      "Epoch 17/100\n",
      "1496/1496 [==============================] - 0s 100us/step - loss: 0.6322 - acc: 0.6604 - val_loss: 0.6651 - val_acc: 0.5569\n",
      "Epoch 18/100\n",
      "1496/1496 [==============================] - 0s 139us/step - loss: 0.6313 - acc: 0.6591 - val_loss: 0.6514 - val_acc: 0.6168\n",
      "Epoch 19/100\n",
      "1496/1496 [==============================] - 0s 113us/step - loss: 0.6304 - acc: 0.6604 - val_loss: 0.6230 - val_acc: 0.7365\n",
      "Epoch 20/100\n",
      "1496/1496 [==============================] - 0s 103us/step - loss: 0.6261 - acc: 0.6644 - val_loss: 0.6813 - val_acc: 0.5449\n",
      "Epoch 21/100\n",
      "1496/1496 [==============================] - 0s 108us/step - loss: 0.6311 - acc: 0.6624 - val_loss: 0.6166 - val_acc: 0.7485\n",
      "Epoch 22/100\n",
      "1496/1496 [==============================] - 0s 102us/step - loss: 0.6264 - acc: 0.6611 - val_loss: 0.6271 - val_acc: 0.7305\n",
      "Epoch 23/100\n",
      "1496/1496 [==============================] - 0s 105us/step - loss: 0.6282 - acc: 0.6571 - val_loss: 0.5966 - val_acc: 0.7665\n",
      "Epoch 24/100\n",
      "1496/1496 [==============================] - 0s 102us/step - loss: 0.6276 - acc: 0.6484 - val_loss: 0.6986 - val_acc: 0.4850\n",
      "Epoch 25/100\n",
      "1496/1496 [==============================] - 0s 103us/step - loss: 0.6260 - acc: 0.6591 - val_loss: 0.6183 - val_acc: 0.7365\n",
      "Epoch 26/100\n",
      "1496/1496 [==============================] - 0s 104us/step - loss: 0.6279 - acc: 0.6591 - val_loss: 0.6806 - val_acc: 0.5329\n",
      "Epoch 27/100\n",
      "1496/1496 [==============================] - 0s 105us/step - loss: 0.6233 - acc: 0.6571 - val_loss: 0.6320 - val_acc: 0.6707\n",
      "Epoch 28/100\n",
      "1496/1496 [==============================] - 0s 106us/step - loss: 0.6292 - acc: 0.6430 - val_loss: 0.6205 - val_acc: 0.7365\n",
      "Epoch 29/100\n",
      "1496/1496 [==============================] - 0s 99us/step - loss: 0.6336 - acc: 0.6477 - val_loss: 0.6136 - val_acc: 0.7904\n",
      "Epoch 30/100\n",
      "1496/1496 [==============================] - 0s 115us/step - loss: 0.6273 - acc: 0.6551 - val_loss: 0.6966 - val_acc: 0.4611\n",
      "Epoch 31/100\n",
      "1496/1496 [==============================] - 0s 104us/step - loss: 0.6279 - acc: 0.6537 - val_loss: 0.6960 - val_acc: 0.4790\n",
      "Epoch 32/100\n",
      "1496/1496 [==============================] - 0s 106us/step - loss: 0.6253 - acc: 0.6751 - val_loss: 0.6375 - val_acc: 0.6647\n",
      "Epoch 33/100\n",
      "1496/1496 [==============================] - 0s 103us/step - loss: 0.6234 - acc: 0.6584 - val_loss: 0.6432 - val_acc: 0.6347\n",
      "Epoch 34/100\n",
      "1496/1496 [==============================] - 0s 106us/step - loss: 0.6215 - acc: 0.6537 - val_loss: 0.6346 - val_acc: 0.6886\n",
      "Epoch 35/100\n",
      "1496/1496 [==============================] - 0s 107us/step - loss: 0.6225 - acc: 0.6551 - val_loss: 0.6587 - val_acc: 0.5629\n",
      "Epoch 36/100\n",
      "1496/1496 [==============================] - 0s 113us/step - loss: 0.6214 - acc: 0.6671 - val_loss: 0.7700 - val_acc: 0.3713\n",
      "Epoch 37/100\n",
      "1496/1496 [==============================] - 0s 113us/step - loss: 0.6251 - acc: 0.6544 - val_loss: 0.6432 - val_acc: 0.6168\n",
      "Epoch 38/100\n",
      "1496/1496 [==============================] - 0s 136us/step - loss: 0.6253 - acc: 0.6584 - val_loss: 0.6174 - val_acc: 0.7964\n",
      "Epoch 39/100\n",
      "1496/1496 [==============================] - 0s 109us/step - loss: 0.6212 - acc: 0.6738 - val_loss: 0.6545 - val_acc: 0.5808\n",
      "Epoch 40/100\n",
      "1496/1496 [==============================] - 0s 105us/step - loss: 0.6286 - acc: 0.6337 - val_loss: 0.6574 - val_acc: 0.5808\n",
      "Epoch 41/100\n",
      "1496/1496 [==============================] - 0s 109us/step - loss: 0.6227 - acc: 0.6718 - val_loss: 0.7323 - val_acc: 0.3892\n",
      "Epoch 42/100\n",
      "1496/1496 [==============================] - 0s 113us/step - loss: 0.6219 - acc: 0.6544 - val_loss: 0.6624 - val_acc: 0.5569\n",
      "Epoch 43/100\n",
      "1496/1496 [==============================] - 0s 113us/step - loss: 0.6272 - acc: 0.6517 - val_loss: 0.6263 - val_acc: 0.7126\n",
      "Epoch 44/100\n",
      "1496/1496 [==============================] - 0s 112us/step - loss: 0.6208 - acc: 0.6598 - val_loss: 0.7679 - val_acc: 0.3772\n",
      "Epoch 45/100\n",
      "1496/1496 [==============================] - 0s 117us/step - loss: 0.6228 - acc: 0.6571 - val_loss: 0.6239 - val_acc: 0.7006\n",
      "Epoch 46/100\n",
      "1496/1496 [==============================] - 0s 118us/step - loss: 0.6232 - acc: 0.6658 - val_loss: 0.6201 - val_acc: 0.6946\n",
      "Epoch 47/100\n",
      "1496/1496 [==============================] - 0s 121us/step - loss: 0.6223 - acc: 0.6551 - val_loss: 0.7580 - val_acc: 0.3713\n",
      "Epoch 48/100\n",
      "1496/1496 [==============================] - 0s 111us/step - loss: 0.6217 - acc: 0.6631 - val_loss: 0.6328 - val_acc: 0.6766\n",
      "Epoch 49/100\n",
      "1496/1496 [==============================] - 0s 111us/step - loss: 0.6224 - acc: 0.6618 - val_loss: 0.6699 - val_acc: 0.5449\n",
      "Epoch 50/100\n",
      "1496/1496 [==============================] - 0s 109us/step - loss: 0.6199 - acc: 0.6651 - val_loss: 0.7911 - val_acc: 0.3713\n",
      "Epoch 51/100\n",
      "1496/1496 [==============================] - 0s 113us/step - loss: 0.6236 - acc: 0.6658 - val_loss: 0.6233 - val_acc: 0.7066\n",
      "Epoch 52/100\n",
      "1496/1496 [==============================] - 0s 105us/step - loss: 0.6224 - acc: 0.6624 - val_loss: 0.7193 - val_acc: 0.4311\n",
      "Epoch 53/100\n",
      "1496/1496 [==============================] - 0s 115us/step - loss: 0.6246 - acc: 0.6584 - val_loss: 0.6280 - val_acc: 0.7066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "1496/1496 [==============================] - 0s 111us/step - loss: 0.6231 - acc: 0.6638 - val_loss: 0.6738 - val_acc: 0.5509\n",
      "Epoch 55/100\n",
      "1496/1496 [==============================] - 0s 111us/step - loss: 0.6199 - acc: 0.6691 - val_loss: 0.6546 - val_acc: 0.5868\n",
      "Epoch 56/100\n",
      "1496/1496 [==============================] - 0s 121us/step - loss: 0.6204 - acc: 0.6711 - val_loss: 0.6608 - val_acc: 0.5629\n",
      "Epoch 57/100\n",
      "1496/1496 [==============================] - ETA: 0s - loss: 0.6238 - acc: 0.653 - 0s 126us/step - loss: 0.6213 - acc: 0.6544 - val_loss: 0.7222 - val_acc: 0.4251\n",
      "Epoch 58/100\n",
      "1496/1496 [==============================] - 0s 107us/step - loss: 0.6204 - acc: 0.6671 - val_loss: 0.6996 - val_acc: 0.4790\n",
      "Epoch 59/100\n",
      "1496/1496 [==============================] - 0s 114us/step - loss: 0.6202 - acc: 0.6644 - val_loss: 0.6216 - val_acc: 0.7066\n",
      "Epoch 60/100\n",
      "1496/1496 [==============================] - 0s 103us/step - loss: 0.6219 - acc: 0.6638 - val_loss: 0.7483 - val_acc: 0.3832\n",
      "Epoch 61/100\n",
      "1496/1496 [==============================] - 0s 106us/step - loss: 0.6209 - acc: 0.6664 - val_loss: 0.6699 - val_acc: 0.5389\n",
      "Epoch 62/100\n",
      "1496/1496 [==============================] - 0s 111us/step - loss: 0.6177 - acc: 0.6691 - val_loss: 0.6817 - val_acc: 0.5210\n",
      "Epoch 63/100\n",
      "1496/1496 [==============================] - 0s 106us/step - loss: 0.6165 - acc: 0.6664 - val_loss: 0.7129 - val_acc: 0.4850\n",
      "Epoch 64/100\n",
      "1496/1496 [==============================] - 0s 102us/step - loss: 0.6157 - acc: 0.6638 - val_loss: 0.7401 - val_acc: 0.4311\n",
      "Epoch 65/100\n",
      "1496/1496 [==============================] - 0s 104us/step - loss: 0.6192 - acc: 0.6671 - val_loss: 0.6916 - val_acc: 0.5389\n",
      "Epoch 66/100\n",
      "1496/1496 [==============================] - 0s 118us/step - loss: 0.6185 - acc: 0.6651 - val_loss: 0.6142 - val_acc: 0.6946\n",
      "Epoch 67/100\n",
      "1496/1496 [==============================] - 0s 107us/step - loss: 0.6127 - acc: 0.6758 - val_loss: 0.6620 - val_acc: 0.5808\n",
      "Epoch 68/100\n",
      "1496/1496 [==============================] - 0s 106us/step - loss: 0.6106 - acc: 0.6745 - val_loss: 0.7746 - val_acc: 0.3892\n",
      "Epoch 69/100\n",
      "1496/1496 [==============================] - 0s 106us/step - loss: 0.6141 - acc: 0.6738 - val_loss: 0.7203 - val_acc: 0.4731\n",
      "Epoch 70/100\n",
      "1496/1496 [==============================] - 0s 106us/step - loss: 0.6137 - acc: 0.6711 - val_loss: 0.7072 - val_acc: 0.5150\n",
      "Epoch 71/100\n",
      "1496/1496 [==============================] - 0s 109us/step - loss: 0.6147 - acc: 0.6644 - val_loss: 0.6935 - val_acc: 0.5569\n",
      "Epoch 72/100\n",
      "1496/1496 [==============================] - 0s 115us/step - loss: 0.6155 - acc: 0.6745 - val_loss: 0.7166 - val_acc: 0.5030\n",
      "Epoch 73/100\n",
      "1496/1496 [==============================] - 0s 108us/step - loss: 0.6118 - acc: 0.6825 - val_loss: 0.7056 - val_acc: 0.5030\n",
      "Epoch 74/100\n",
      "1496/1496 [==============================] - 0s 107us/step - loss: 0.6087 - acc: 0.6818 - val_loss: 0.6978 - val_acc: 0.5449\n",
      "Epoch 75/100\n",
      "1496/1496 [==============================] - 0s 118us/step - loss: 0.6051 - acc: 0.6805 - val_loss: 0.7342 - val_acc: 0.4611\n",
      "Epoch 76/100\n",
      "1496/1496 [==============================] - 0s 128us/step - loss: 0.6011 - acc: 0.6798 - val_loss: 0.5775 - val_acc: 0.7186\n",
      "Epoch 77/100\n",
      "1496/1496 [==============================] - 0s 106us/step - loss: 0.6064 - acc: 0.6791 - val_loss: 0.7522 - val_acc: 0.4192\n",
      "Epoch 78/100\n",
      "1496/1496 [==============================] - 0s 118us/step - loss: 0.6080 - acc: 0.6698 - val_loss: 0.5978 - val_acc: 0.7126\n",
      "Epoch 79/100\n",
      "1496/1496 [==============================] - 0s 107us/step - loss: 0.6058 - acc: 0.6738 - val_loss: 0.6366 - val_acc: 0.6467\n",
      "Epoch 80/100\n",
      "1496/1496 [==============================] - 0s 109us/step - loss: 0.6089 - acc: 0.6678 - val_loss: 0.6641 - val_acc: 0.6168\n",
      "Epoch 81/100\n",
      "1496/1496 [==============================] - 0s 109us/step - loss: 0.6012 - acc: 0.6785 - val_loss: 0.6607 - val_acc: 0.6168\n",
      "Epoch 82/100\n",
      "1496/1496 [==============================] - 0s 111us/step - loss: 0.6000 - acc: 0.6892 - val_loss: 0.7322 - val_acc: 0.4431\n",
      "Epoch 83/100\n",
      "1496/1496 [==============================] - 0s 117us/step - loss: 0.5964 - acc: 0.6905 - val_loss: 0.6796 - val_acc: 0.6168\n",
      "Epoch 84/100\n",
      "1496/1496 [==============================] - 0s 115us/step - loss: 0.5949 - acc: 0.6925 - val_loss: 0.6491 - val_acc: 0.6527\n",
      "Epoch 85/100\n",
      "1496/1496 [==============================] - 0s 116us/step - loss: 0.6002 - acc: 0.6785 - val_loss: 0.6007 - val_acc: 0.6647\n",
      "Epoch 86/100\n",
      "1496/1496 [==============================] - 0s 114us/step - loss: 0.5956 - acc: 0.6912 - val_loss: 0.6176 - val_acc: 0.6527\n",
      "Epoch 87/100\n",
      "1496/1496 [==============================] - 0s 114us/step - loss: 0.6066 - acc: 0.6671 - val_loss: 0.6724 - val_acc: 0.5988\n",
      "Epoch 88/100\n",
      "1496/1496 [==============================] - 0s 107us/step - loss: 0.5902 - acc: 0.6918 - val_loss: 0.6774 - val_acc: 0.6287\n",
      "Epoch 89/100\n",
      "1496/1496 [==============================] - 0s 124us/step - loss: 0.6005 - acc: 0.6745 - val_loss: 0.6488 - val_acc: 0.6347\n",
      "Epoch 90/100\n",
      "1496/1496 [==============================] - 0s 121us/step - loss: 0.5903 - acc: 0.6992 - val_loss: 0.6619 - val_acc: 0.6168\n",
      "Epoch 91/100\n",
      "1496/1496 [==============================] - 0s 119us/step - loss: 0.5872 - acc: 0.6952 - val_loss: 0.6496 - val_acc: 0.6587\n",
      "Epoch 92/100\n",
      "1496/1496 [==============================] - 0s 121us/step - loss: 0.5922 - acc: 0.6878 - val_loss: 0.6261 - val_acc: 0.6108\n",
      "Epoch 93/100\n",
      "1496/1496 [==============================] - 0s 107us/step - loss: 0.5870 - acc: 0.7012 - val_loss: 0.6252 - val_acc: 0.6228\n",
      "Epoch 94/100\n",
      "1496/1496 [==============================] - 0s 128us/step - loss: 0.5823 - acc: 0.6999 - val_loss: 0.6751 - val_acc: 0.5928\n",
      "Epoch 95/100\n",
      "1496/1496 [==============================] - 0s 123us/step - loss: 0.5901 - acc: 0.6898 - val_loss: 0.7392 - val_acc: 0.5329\n",
      "Epoch 96/100\n",
      "1496/1496 [==============================] - 0s 117us/step - loss: 0.5872 - acc: 0.6959 - val_loss: 0.7079 - val_acc: 0.5749\n",
      "Epoch 97/100\n",
      "1496/1496 [==============================] - 0s 114us/step - loss: 0.5853 - acc: 0.6972 - val_loss: 0.6275 - val_acc: 0.6527\n",
      "Epoch 98/100\n",
      "1496/1496 [==============================] - 0s 114us/step - loss: 0.5889 - acc: 0.6858 - val_loss: 0.6027 - val_acc: 0.6527\n",
      "Epoch 99/100\n",
      "1496/1496 [==============================] - 0s 105us/step - loss: 0.5809 - acc: 0.7005 - val_loss: 0.6851 - val_acc: 0.5629\n",
      "Epoch 100/100\n",
      "1496/1496 [==============================] - 0s 107us/step - loss: 0.5816 - acc: 0.6992 - val_loss: 0.7063 - val_acc: 0.4910\n",
      "713/713 [==============================] - 0s 24us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8006417717873465, 0.4754558205604553]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple lstm network learning\n",
    "model = Sequential()\n",
    "model.add(LSTM(36, input_shape=(1, 12)))\n",
    "for i in range(3):\n",
    "    model.add(Dense(36,activation='tanh'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16,validation_split=0.1)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47545582047685836"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,np.where(model.predict(X_test)>0.5,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Close      Open      High       Low    Volume    Change      time  \\\n",
      "Close   1.000000  0.996446  0.998221  0.998874 -0.191077  0.044403 -0.478836   \n",
      "Open    0.996446  1.000000  0.998831  0.998275 -0.179547 -0.020743 -0.474610   \n",
      "High    0.998221  0.998831  1.000000  0.998460 -0.180676  0.002485 -0.472235   \n",
      "Low     0.998874  0.998275  0.998460  1.000000 -0.188229  0.020353 -0.481540   \n",
      "Volume -0.191077 -0.179547 -0.180676 -0.188229  1.000000 -0.140412  0.334251   \n",
      "Change  0.044403 -0.020743  0.002485  0.020353 -0.140412  1.000000 -0.053309   \n",
      "time   -0.478836 -0.474610 -0.472235 -0.481540  0.334251 -0.053309  1.000000   \n",
      "kdj_k   0.152060  0.120238  0.124309  0.146136 -0.045018  0.454928 -0.165760   \n",
      "kdj_d   0.180799  0.166844  0.163661  0.182094  0.010695  0.198027 -0.187602   \n",
      "kdj_j   0.187990  0.179779  0.174726  0.191161  0.029316  0.114442 -0.193374   \n",
      "MA_26   0.947727  0.951487  0.953706  0.946963 -0.182765 -0.065248 -0.424092   \n",
      "MA_52   0.904037  0.906769  0.910609  0.901796 -0.180077 -0.058099 -0.351529   \n",
      "y      -0.596447 -0.584512 -0.585316 -0.593218  0.363844 -0.155553  0.547428   \n",
      "\n",
      "           kdj_k     kdj_d     kdj_j     MA_26     MA_52         y  \n",
      "Close   0.152060  0.180799  0.187990  0.947727  0.904037 -0.596447  \n",
      "Open    0.120238  0.166844  0.179779  0.951487  0.906769 -0.584512  \n",
      "High    0.124309  0.163661  0.174726  0.953706  0.910609 -0.585316  \n",
      "Low     0.146136  0.182094  0.191161  0.946963  0.901796 -0.593218  \n",
      "Volume -0.045018  0.010695  0.029316 -0.182765 -0.180077  0.363844  \n",
      "Change  0.454928  0.198027  0.114442 -0.065248 -0.058099 -0.155553  \n",
      "time   -0.165760 -0.187602 -0.193374 -0.424092 -0.351529  0.547428  \n",
      "kdj_k   1.000000  0.910566  0.825720 -0.120555 -0.137469 -0.391989  \n",
      "kdj_d   0.910566  1.000000  0.982841 -0.109468 -0.147044 -0.382840  \n",
      "kdj_j   0.825720  0.982841  1.000000 -0.097807 -0.146237 -0.362391  \n",
      "MA_26  -0.120555 -0.109468 -0.097807  1.000000  0.974286 -0.492213  \n",
      "MA_52  -0.137469 -0.147044 -0.146237  0.974286  1.000000 -0.456516  \n",
      "y      -0.391989 -0.382840 -0.362391 -0.492213 -0.456516  1.000000  \n"
     ]
    }
   ],
   "source": [
    "X_test2\n",
    "corrMatt =X_test2.corr()\n",
    "print(corrMatt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713,)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MA_26=df[\"Close\"].rolling(26).mean()\n",
    "MA_26=MA_26.dropna()\n",
    "MA_26.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(789, 6)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713,)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MA_26.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 12)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feature_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-3ee5b5034f23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeaturre_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Fare'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
