{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import FinanceDataReader as fdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63 samples, validate on 7 samples\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.6725 - acc: 0.6032 - val_loss: 0.8002 - val_acc: 0.2857\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 602us/step - loss: 0.6734 - acc: 0.6032 - val_loss: 0.7881 - val_acc: 0.2857\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 617us/step - loss: 0.6722 - acc: 0.6032 - val_loss: 0.7925 - val_acc: 0.2857\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 617us/step - loss: 0.6740 - acc: 0.6032 - val_loss: 0.7869 - val_acc: 0.2857\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 665us/step - loss: 0.6719 - acc: 0.6032 - val_loss: 0.7931 - val_acc: 0.2857\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 617us/step - loss: 0.6719 - acc: 0.6032 - val_loss: 0.8007 - val_acc: 0.2857\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 617us/step - loss: 0.6716 - acc: 0.6032 - val_loss: 0.8048 - val_acc: 0.2857\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 665us/step - loss: 0.6720 - acc: 0.6032 - val_loss: 0.8082 - val_acc: 0.2857\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 633us/step - loss: 0.6719 - acc: 0.6032 - val_loss: 0.8135 - val_acc: 0.2857\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.6721 - acc: 0.6032 - val_loss: 0.8115 - val_acc: 0.2857\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6718 - acc: 0.6032 - val_loss: 0.8117 - val_acc: 0.2857\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.6721 - acc: 0.6032 - val_loss: 0.8130 - val_acc: 0.2857\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 649us/step - loss: 0.6720 - acc: 0.6032 - val_loss: 0.8076 - val_acc: 0.2857\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 665us/step - loss: 0.6718 - acc: 0.6032 - val_loss: 0.8077 - val_acc: 0.2857\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 665us/step - loss: 0.6721 - acc: 0.6032 - val_loss: 0.8022 - val_acc: 0.2857\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 665us/step - loss: 0.6723 - acc: 0.6032 - val_loss: 0.8066 - val_acc: 0.2857\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 649us/step - loss: 0.6723 - acc: 0.6032 - val_loss: 0.8063 - val_acc: 0.2857\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 697us/step - loss: 0.6735 - acc: 0.6032 - val_loss: 0.7962 - val_acc: 0.2857\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6723 - acc: 0.6032 - val_loss: 0.7945 - val_acc: 0.2857\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6717 - acc: 0.6032 - val_loss: 0.7987 - val_acc: 0.2857\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.6723 - acc: 0.6032 - val_loss: 0.8059 - val_acc: 0.2857\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 665us/step - loss: 0.6721 - acc: 0.6032 - val_loss: 0.8097 - val_acc: 0.2857\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 697us/step - loss: 0.6735 - acc: 0.6032 - val_loss: 0.8171 - val_acc: 0.2857\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.6722 - acc: 0.6032 - val_loss: 0.8097 - val_acc: 0.2857\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6718 - acc: 0.6032 - val_loss: 0.8062 - val_acc: 0.2857\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6720 - acc: 0.6032 - val_loss: 0.8053 - val_acc: 0.2857\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 902us/step - loss: 0.6724 - acc: 0.6032 - val_loss: 0.7993 - val_acc: 0.2857\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 887us/step - loss: 0.6729 - acc: 0.6032 - val_loss: 0.8048 - val_acc: 0.2857\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.6718 - acc: 0.6032 - val_loss: 0.8061 - val_acc: 0.2857\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.6722 - acc: 0.6032 - val_loss: 0.8062 - val_acc: 0.2857\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6719 - acc: 0.6032 - val_loss: 0.8030 - val_acc: 0.2857\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 697us/step - loss: 0.6717 - acc: 0.6032 - val_loss: 0.8018 - val_acc: 0.2857\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6721 - acc: 0.6032 - val_loss: 0.8010 - val_acc: 0.2857\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.6719 - acc: 0.6032 - val_loss: 0.8026 - val_acc: 0.2857\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.6721 - acc: 0.6032 - val_loss: 0.8002 - val_acc: 0.2857\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.6719 - acc: 0.6032 - val_loss: 0.8036 - val_acc: 0.2857\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 807us/step - loss: 0.6721 - acc: 0.6032 - val_loss: 0.8050 - val_acc: 0.2857\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 807us/step - loss: 0.6718 - acc: 0.6032 - val_loss: 0.8067 - val_acc: 0.2857\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 807us/step - loss: 0.6719 - acc: 0.6032 - val_loss: 0.8075 - val_acc: 0.2857\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.6738 - acc: 0.6032 - val_loss: 0.8012 - val_acc: 0.2857\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.6718 - acc: 0.6032 - val_loss: 0.8016 - val_acc: 0.2857\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.6721 - acc: 0.6032 - val_loss: 0.8067 - val_acc: 0.2857\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 649us/step - loss: 0.6720 - acc: 0.6032 - val_loss: 0.8093 - val_acc: 0.2857\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 697us/step - loss: 0.6723 - acc: 0.6032 - val_loss: 0.8120 - val_acc: 0.2857\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6720 - acc: 0.6032 - val_loss: 0.8101 - val_acc: 0.2857\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.6732 - acc: 0.6032 - val_loss: 0.8000 - val_acc: 0.2857\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.6719 - acc: 0.6032 - val_loss: 0.8029 - val_acc: 0.2857\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.6720 - acc: 0.6032 - val_loss: 0.7998 - val_acc: 0.2857\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6719 - acc: 0.6032 - val_loss: 0.8023 - val_acc: 0.2857\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6720 - acc: 0.6032 - val_loss: 0.8040 - val_acc: 0.2857\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.6732 - acc: 0.6032 - val_loss: 0.8109 - val_acc: 0.2857\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6718 - acc: 0.6032 - val_loss: 0.8094 - val_acc: 0.2857\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6718 - acc: 0.6032 - val_loss: 0.8044 - val_acc: 0.2857\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 997us/step - loss: 0.6733 - acc: 0.6032 - val_loss: 0.7953 - val_acc: 0.2857\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 760us/step - loss: 0.6722 - acc: 0.6032 - val_loss: 0.8004 - val_acc: 0.2857\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.6728 - acc: 0.6032 - val_loss: 0.8053 - val_acc: 0.2857\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.6733 - acc: 0.6032 - val_loss: 0.7985 - val_acc: 0.2857\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.6729 - acc: 0.6032 - val_loss: 0.8051 - val_acc: 0.2857\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6729 - acc: 0.6032 - val_loss: 0.7971 - val_acc: 0.2857\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 697us/step - loss: 0.6720 - acc: 0.6032 - val_loss: 0.8016 - val_acc: 0.2857\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 697us/step - loss: 0.6716 - acc: 0.6032 - val_loss: 0.8013 - val_acc: 0.2857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 697us/step - loss: 0.6715 - acc: 0.6032 - val_loss: 0.8021 - val_acc: 0.2857\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.6718 - acc: 0.6032 - val_loss: 0.8019 - val_acc: 0.2857\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 697us/step - loss: 0.6720 - acc: 0.6032 - val_loss: 0.8013 - val_acc: 0.2857\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 649us/step - loss: 0.6716 - acc: 0.6032 - val_loss: 0.8032 - val_acc: 0.2857\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 617us/step - loss: 0.6714 - acc: 0.6032 - val_loss: 0.8039 - val_acc: 0.2857\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 617us/step - loss: 0.6713 - acc: 0.6032 - val_loss: 0.8046 - val_acc: 0.2857\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 602us/step - loss: 0.6714 - acc: 0.6032 - val_loss: 0.8014 - val_acc: 0.2857\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 665us/step - loss: 0.6720 - acc: 0.6032 - val_loss: 0.7961 - val_acc: 0.2857\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 617us/step - loss: 0.6714 - acc: 0.6032 - val_loss: 0.7991 - val_acc: 0.2857\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 617us/step - loss: 0.6713 - acc: 0.6032 - val_loss: 0.8019 - val_acc: 0.2857\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 617us/step - loss: 0.6713 - acc: 0.6032 - val_loss: 0.8050 - val_acc: 0.2857\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 665us/step - loss: 0.6708 - acc: 0.6032 - val_loss: 0.8049 - val_acc: 0.2857\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.6709 - acc: 0.6032 - val_loss: 0.8049 - val_acc: 0.2857\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 649us/step - loss: 0.6714 - acc: 0.6032 - val_loss: 0.8037 - val_acc: 0.2857\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 617us/step - loss: 0.6723 - acc: 0.6032 - val_loss: 0.8074 - val_acc: 0.2857\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.6730 - acc: 0.6032 - val_loss: 0.7992 - val_acc: 0.2857\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.6719 - acc: 0.6032 - val_loss: 0.8030 - val_acc: 0.2857\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.6713 - acc: 0.6032 - val_loss: 0.8028 - val_acc: 0.2857\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 665us/step - loss: 0.6718 - acc: 0.6032 - val_loss: 0.7976 - val_acc: 0.2857\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 617us/step - loss: 0.6718 - acc: 0.6032 - val_loss: 0.8015 - val_acc: 0.2857\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 617us/step - loss: 0.6714 - acc: 0.6032 - val_loss: 0.7999 - val_acc: 0.2857\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 602us/step - loss: 0.6711 - acc: 0.6032 - val_loss: 0.8006 - val_acc: 0.2857\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.6708 - acc: 0.6032 - val_loss: 0.8020 - val_acc: 0.2857\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.6711 - acc: 0.6032 - val_loss: 0.7974 - val_acc: 0.2857\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.6711 - acc: 0.6032 - val_loss: 0.7922 - val_acc: 0.2857\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.6714 - acc: 0.6032 - val_loss: 0.7951 - val_acc: 0.2857\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 649us/step - loss: 0.6713 - acc: 0.6032 - val_loss: 0.7972 - val_acc: 0.2857\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 633us/step - loss: 0.6713 - acc: 0.6032 - val_loss: 0.7979 - val_acc: 0.2857\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 633us/step - loss: 0.6709 - acc: 0.6032 - val_loss: 0.8043 - val_acc: 0.2857\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 649us/step - loss: 0.6698 - acc: 0.6032 - val_loss: 0.8035 - val_acc: 0.2857\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 649us/step - loss: 0.6714 - acc: 0.6032 - val_loss: 0.8051 - val_acc: 0.2857\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 649us/step - loss: 0.6725 - acc: 0.6032 - val_loss: 0.8102 - val_acc: 0.2857\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 823us/step - loss: 0.6717 - acc: 0.6032 - val_loss: 0.8044 - val_acc: 0.2857\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 887us/step - loss: 0.6710 - acc: 0.6032 - val_loss: 0.7978 - val_acc: 0.2857\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 871us/step - loss: 0.6697 - acc: 0.6032 - val_loss: 0.7951 - val_acc: 0.2857\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.6707 - acc: 0.6032 - val_loss: 0.7953 - val_acc: 0.2857\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 649us/step - loss: 0.6708 - acc: 0.6032 - val_loss: 0.7929 - val_acc: 0.2857\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 696us/step - loss: 0.6710 - acc: 0.6032 - val_loss: 0.7949 - val_acc: 0.2857\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.6706 - acc: 0.6032 - val_loss: 0.7978 - val_acc: 0.2857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.40201932],\n",
       "       [0.4020234 ],\n",
       "       [0.4020322 ],\n",
       "       [0.40203038],\n",
       "       [0.40203148],\n",
       "       [0.4020443 ],\n",
       "       [0.4020436 ],\n",
       "       [0.40204528],\n",
       "       [0.40203816],\n",
       "       [0.4020554 ],\n",
       "       [0.40205804],\n",
       "       [0.40206504],\n",
       "       [0.4020695 ],\n",
       "       [0.40207535],\n",
       "       [0.40207458],\n",
       "       [0.40208238],\n",
       "       [0.40208393],\n",
       "       [0.402088  ],\n",
       "       [0.40209168],\n",
       "       [0.40209585],\n",
       "       [0.40210462],\n",
       "       [0.4021048 ],\n",
       "       [0.4020958 ],\n",
       "       [0.40210062],\n",
       "       [0.4021147 ],\n",
       "       [0.40211794],\n",
       "       [0.40211886],\n",
       "       [0.40212363],\n",
       "       [0.4021069 ],\n",
       "       [0.40210375]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH = 25\n",
    "# many to one 성공@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "df = fdr.DataReader(\"IXIC\",\"2009-01-01\",\"2019-01-01\")\n",
    "df=df[0:-(len(df)%BATCH)]\n",
    "\n",
    "\n",
    "y=[]\n",
    "for x in range(1,10001):\n",
    "    try:\n",
    "        y.append(np.where(df[\"Change\"][-1+(BATCH*x)]>0,1,0))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df = df.values\n",
    "df.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df = scaler.fit_transform(df)\n",
    "\n",
    "train_size=int((df.shape[0]/BATCH)*0.7)*BATCH\n",
    "X_train=df[0:train_size]\n",
    "X_test=df[train_size:]\n",
    "y_train=y[0:int(train_size/BATCH)]\n",
    "y_test=y[int(train_size/BATCH):]\n",
    "\n",
    "# many to one 전처리 필요\n",
    "y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "X_train = np.reshape(X_train, (int(X_train.shape[0]/BATCH),BATCH, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (int(X_test.shape[0]/BATCH),BATCH, X_test.shape[1]))\n",
    "# simple lstm network learning\n",
    "model = Sequential()\n",
    "model.add(LSTM(36, input_shape=(BATCH, 6)))\n",
    "for i in range(5):\n",
    "    model.add(Dense(36,activation='sigmoid'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16,validation_split=0.1)\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:,24,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many to one 성공@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "df = fdr.DataReader(\"KS11\",\"2018-06-01\",\"2019-01-01\")\n",
    "df=df[0:-(len(df)%20)]\n",
    "\n",
    "\n",
    "y=[]\n",
    "for x in range(1,10001):\n",
    "    try:\n",
    "        y.append(np.where(df[\"Change\"][(x*19)]>0,1,0))\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0131"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Change\"][139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(1), array(1), array(1), array(0), array(1), array(1)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 6)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "140",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 140",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-3bcda6f6dc3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 140"
     ]
    }
   ],
   "source": [
    "df[140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
