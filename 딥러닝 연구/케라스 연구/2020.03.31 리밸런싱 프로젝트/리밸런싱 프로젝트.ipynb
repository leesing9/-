{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import FinanceDataReader as fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특성 추가 ------------------------------------------\n",
    "    #이동평균선\n",
    "def get_MA(df):\n",
    "    MA_26=df[\"Close\"].rolling(26).mean()\n",
    "    MA_52=df[\"Close\"].rolling(52).mean()\n",
    "    df=df.assign(MA_26=MA_26,MA_52=MA_52).dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "    #스토캐스틱\n",
    "def get_stochastic(df, n=15, m=5, t=3):\n",
    "    # n일중 최고가\n",
    "    ndays_high = df.High.rolling(window=n, min_periods=1).max()\n",
    "    # n일중 최저가\n",
    "    ndays_low = df.Low.rolling(window=n, min_periods=1).min()\n",
    " \n",
    "    # Fast%K 계산\n",
    "    kdj_k = ((df.Close - ndays_low) / (ndays_high - ndays_low))*100\n",
    "    # Fast%D (=Slow%K) 계산\n",
    "    kdj_d = kdj_k.ewm(span=m).mean()\n",
    "    # Slow%D 계산\n",
    "    kdj_j = kdj_d.ewm(span=t).mean()\n",
    " \n",
    "    # dataframe에 컬럼 추가\n",
    "    df = df.assign(kdj_k=kdj_k, kdj_d=kdj_d, kdj_j=kdj_j).dropna()\n",
    "    \n",
    "    return df\n",
    "   \n",
    "    #시간\n",
    "def get_time(df):\n",
    "    time=np.linspace(0,10,len(df),endpoint=False).reshape(-1,1)\n",
    "    df=df.assign(time=time)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS11 = fdr.DataReader(\"KS11\",\"2009-01-01\",\"2019-01-01\")\n",
    "KQ11= fdr.DataReader(\"KQ11\",\"2009-01-01\",\"2019-01-01\")\n",
    "US500 = fdr.DataReader(\"US500\",\"2009-01-01\",\"2019-01-01\")\n",
    "HSI = fdr.DataReader(\"HSI\",\"2009-01-01\",\"2019-01-01\")\n",
    "IXIC = fdr.DataReader(\"IXIC\",\"2009-01-01\",\"2019-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS11 = fdr.DataReader(\"KS11\",\"2009-01-01\",\"2019-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dic={}\n",
    "for x,y in zip([KS11,KQ11,HSI,US500,IXIC],[\"KS11\",\"KQ11\",\"HSI\",\"US500\",\"IXIC\"]):\n",
    "    a=get_time(get_stochastic(get_MA(x)))\n",
    "    index_dic[y]=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13 samples, validate on 2 samples\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 44s 3s/step - loss: 0.4748 - acc: 1.0000 - val_loss: 0.4535 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4535 - acc: 1.0000 - val_loss: 0.4330 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4330 - acc: 1.0000 - val_loss: 0.4133 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4133 - acc: 1.0000 - val_loss: 0.3943 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3943 - acc: 1.0000 - val_loss: 0.3762 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3762 - acc: 1.0000 - val_loss: 0.3588 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3588 - acc: 1.0000 - val_loss: 0.3422 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3422 - acc: 1.0000 - val_loss: 0.3264 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3264 - acc: 1.0000 - val_loss: 0.3112 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3112 - acc: 1.0000 - val_loss: 0.2968 - val_acc: 1.0000\n",
      "19일날 상승예측\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df=index_dic[\"KS11\"]\n",
    "MA_26=df[\"Close\"].rolling(26).mean().dropna()\n",
    "df_before=df[\"Close\"][25:43]\n",
    "y=np.where(df_before.shift(-1)>MA_26[:18].shift(-1),1,0)\n",
    "\n",
    "df = df.values\n",
    "df.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df = scaler.fit_transform(df)\n",
    "X=df[25:43]\n",
    "\n",
    "\n",
    "train_size = int(15)\n",
    "y_train2=y[:train_size]\n",
    "y_test2=y[train_size:]\n",
    "X_train2 = X[:train_size]\n",
    "X_test2 = X[train_size:]\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train2, (X_train2.shape[0], 1, X_train2.shape[1]))\n",
    "X_test = np.reshape(X_test2, (X_test2.shape[0], 1, X_test2.shape[1]))\n",
    "y_train=y_train2\n",
    "y_test=y_test2\n",
    "\n",
    "# simple lstm network learning\n",
    "model = Sequential()\n",
    "model.add(LSTM(36, input_shape=(1, 12)))\n",
    "for i in range(5):\n",
    "    model.add(Dense(36,activation='sigmoid'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=16,validation_split=0.1)\n",
    "\n",
    "\n",
    "\n",
    "if(model.predict(X_test)[-1]>0.5):\n",
    "    print(\"19일날 상승예측\")\n",
    "else:\n",
    "    print(\"19일날 하락예측\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 13 samples, validate on 2 samples\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 0.6812 - acc: 1.0000 - val_loss: 0.6575 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 614us/step - loss: 0.6575 - acc: 1.0000 - val_loss: 0.6310 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 614us/step - loss: 0.6310 - acc: 1.0000 - val_loss: 0.6037 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 691us/step - loss: 0.6037 - acc: 1.0000 - val_loss: 0.5766 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 609us/step - loss: 0.5766 - acc: 1.0000 - val_loss: 0.5499 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 740us/step - loss: 0.5499 - acc: 1.0000 - val_loss: 0.5239 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 768us/step - loss: 0.5239 - acc: 1.0000 - val_loss: 0.4987 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 917us/step - loss: 0.4987 - acc: 1.0000 - val_loss: 0.4744 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 614us/step - loss: 0.4744 - acc: 1.0000 - val_loss: 0.4510 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 537us/step - loss: 0.4510 - acc: 1.0000 - val_loss: 0.4287 - val_acc: 1.0000\n",
      "1번째 리밸런싱 성공\n",
      "5/5 [==============================] - 0s 208us/step\n",
      "Train,Test의 loss, score : [0.5536798238754272, 0.800000011920929]\n",
      "1~20영업일까지를 예측 데이터로 21영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.65138555]\n",
      " [0.651385  ]\n",
      " [0.6513883 ]\n",
      " [0.65138876]\n",
      " [0.6513872 ]]\n",
      "실제 레이어 : [1 1 1 1 0]\n",
      "실제 값 : 0\n",
      "[[0 1]\n",
      " [0 4]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 27 samples, validate on 3 samples\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.6252 - acc: 0.9259 - val_loss: 0.7469 - val_acc: 0.3333\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 626us/step - loss: 0.5792 - acc: 0.9259 - val_loss: 0.7778 - val_acc: 0.3333\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 677us/step - loss: 0.5395 - acc: 0.9259 - val_loss: 0.8118 - val_acc: 0.3333\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 517us/step - loss: 0.4998 - acc: 0.9259 - val_loss: 0.8484 - val_acc: 0.3333\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 591us/step - loss: 0.4663 - acc: 0.9259 - val_loss: 0.8878 - val_acc: 0.3333\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 540us/step - loss: 0.4344 - acc: 0.9259 - val_loss: 0.9291 - val_acc: 0.3333\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 628us/step - loss: 0.4102 - acc: 0.9259 - val_loss: 0.9727 - val_acc: 0.3333\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 517us/step - loss: 0.3869 - acc: 0.9259 - val_loss: 1.0173 - val_acc: 0.3333\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.3668 - acc: 0.9259 - val_loss: 1.0625 - val_acc: 0.3333\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.3496 - acc: 0.9259 - val_loss: 1.1079 - val_acc: 0.3333\n",
      "2번째 리밸런싱 성공\n",
      "10/10 [==============================] - 0s 104us/step\n",
      "Train,Test의 loss, score : [1.0211822986602783, 0.4000000059604645]\n",
      "1~40영업일까지를 예측 데이터로 41영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.78591514]\n",
      " [0.785914  ]\n",
      " [0.78590906]\n",
      " [0.78591883]\n",
      " [0.7859188 ]\n",
      " [0.7859213 ]\n",
      " [0.7859168 ]\n",
      " [0.7859137 ]\n",
      " [0.78591126]\n",
      " [0.78590024]]\n",
      "실제 레이어 : [0 0 1 1 1 1 0 0 0 0]\n",
      "실제 값 : 0\n",
      "[[0 6]\n",
      " [0 4]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 40 samples, validate on 5 samples\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.7597 - acc: 0.2500 - val_loss: 0.6599 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 474us/step - loss: 0.7137 - acc: 0.2500 - val_loss: 0.7075 - val_acc: 0.2000\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 399us/step - loss: 0.6732 - acc: 0.7500 - val_loss: 0.7609 - val_acc: 0.2000\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 474us/step - loss: 0.6372 - acc: 0.7500 - val_loss: 0.8202 - val_acc: 0.2000\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 399us/step - loss: 0.6072 - acc: 0.7500 - val_loss: 0.8821 - val_acc: 0.2000\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 424us/step - loss: 0.5933 - acc: 0.7500 - val_loss: 0.9483 - val_acc: 0.2000\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 425us/step - loss: 0.5814 - acc: 0.7500 - val_loss: 1.0112 - val_acc: 0.2000\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.5704 - acc: 0.7500 - val_loss: 1.0643 - val_acc: 0.2000\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 595us/step - loss: 0.5660 - acc: 0.7500 - val_loss: 1.1062 - val_acc: 0.2000\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.5628 - acc: 0.7500 - val_loss: 1.1352 - val_acc: 0.2000\n",
      "3번째 리밸런싱 성공\n",
      "15/15 [==============================] - 0s 133us/step\n",
      "Train,Test의 loss, score : [0.6493940949440002, 0.6666666865348816]\n",
      "1~60영업일까지를 예측 데이터로 61영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.7390324 ]\n",
      " [0.7390318 ]\n",
      " [0.73903304]\n",
      " [0.7390374 ]\n",
      " [0.7390371 ]\n",
      " [0.73903924]\n",
      " [0.7390406 ]\n",
      " [0.73904216]\n",
      " [0.7390417 ]\n",
      " [0.73904175]\n",
      " [0.7390416 ]\n",
      " [0.73903334]\n",
      " [0.7390344 ]\n",
      " [0.7390383 ]\n",
      " [0.7390396 ]]\n",
      "실제 레이어 : [0 0 1 1 1 1 1 1 1 1 0 0 1 1 0]\n",
      "실제 값 : 0\n",
      "[[ 0  5]\n",
      " [ 0 10]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 54 samples, validate on 6 samples\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.8582 - acc: 0.2963 - val_loss: 0.7940 - val_acc: 0.3333\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 0s 361us/step - loss: 0.7892 - acc: 0.2963 - val_loss: 0.7413 - val_acc: 0.3333\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 0s 277us/step - loss: 0.7348 - acc: 0.2963 - val_loss: 0.7000 - val_acc: 0.3333\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 0s 296us/step - loss: 0.6877 - acc: 0.6667 - val_loss: 0.6714 - val_acc: 0.6667\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 0s 313us/step - loss: 0.6575 - acc: 0.7037 - val_loss: 0.6534 - val_acc: 0.6667\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 0s 296us/step - loss: 0.6357 - acc: 0.7037 - val_loss: 0.6430 - val_acc: 0.6667\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 0s 333us/step - loss: 0.6242 - acc: 0.7037 - val_loss: 0.6377 - val_acc: 0.6667\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 0s 259us/step - loss: 0.6139 - acc: 0.7037 - val_loss: 0.6365 - val_acc: 0.6667\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 0s 277us/step - loss: 0.6093 - acc: 0.7037 - val_loss: 0.6370 - val_acc: 0.6667\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 0s 332us/step - loss: 0.6097 - acc: 0.7037 - val_loss: 0.6384 - val_acc: 0.6667\n",
      "4번째 리밸런싱 성공\n",
      "20/20 [==============================] - 0s 50us/step\n",
      "Train,Test의 loss, score : [0.40437397360801697, 0.949999988079071]\n",
      "1~80영업일까지를 예측 데이터로 81영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.69552815]\n",
      " [0.6955378 ]\n",
      " [0.695536  ]\n",
      " [0.6955384 ]\n",
      " [0.69553965]\n",
      " [0.69553965]\n",
      " [0.69554245]\n",
      " [0.6955407 ]\n",
      " [0.695541  ]\n",
      " [0.69554317]\n",
      " [0.6955454 ]\n",
      " [0.6955441 ]\n",
      " [0.6955419 ]\n",
      " [0.6955368 ]\n",
      " [0.69553787]\n",
      " [0.69554025]\n",
      " [0.69553834]\n",
      " [0.6955403 ]\n",
      " [0.6955326 ]\n",
      " [0.6955321 ]]\n",
      "실제 레이어 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "실제 값 : 0\n",
      "[[ 0  1]\n",
      " [ 0 19]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 8 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.5838 - acc: 0.7313 - val_loss: 0.3108 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 0s 476us/step - loss: 0.5813 - acc: 0.7313 - val_loss: 0.3324 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 0s 447us/step - loss: 0.5825 - acc: 0.7313 - val_loss: 0.3531 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 0s 328us/step - loss: 0.5846 - acc: 0.7313 - val_loss: 0.3609 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 0s 268us/step - loss: 0.5845 - acc: 0.7313 - val_loss: 0.3465 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 0s 268us/step - loss: 0.5836 - acc: 0.7313 - val_loss: 0.3244 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 0s 268us/step - loss: 0.5824 - acc: 0.7313 - val_loss: 0.3095 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 0s 253us/step - loss: 0.5838 - acc: 0.7313 - val_loss: 0.2956 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 0s 298us/step - loss: 0.5824 - acc: 0.7313 - val_loss: 0.3014 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 0s 312us/step - loss: 0.5822 - acc: 0.7313 - val_loss: 0.2986 - val_acc: 1.0000\n",
      "5번째 리밸런싱 성공\n",
      "25/25 [==============================] - 0s 80us/step\n",
      "Train,Test의 loss, score : [0.34084010124206543, 0.9599999785423279]\n",
      "1~100영업일까지를 예측 데이터로 101영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.7418462 ]\n",
      " [0.74184525]\n",
      " [0.7418454 ]\n",
      " [0.7418432 ]\n",
      " [0.7418427 ]\n",
      " [0.74184644]\n",
      " [0.7418368 ]\n",
      " [0.74183834]\n",
      " [0.7418372 ]\n",
      " [0.74184257]\n",
      " [0.74184287]\n",
      " [0.7418463 ]\n",
      " [0.7418439 ]\n",
      " [0.74184674]\n",
      " [0.7418437 ]\n",
      " [0.74184555]\n",
      " [0.74184227]\n",
      " [0.7418475 ]\n",
      " [0.7418447 ]\n",
      " [0.74184513]\n",
      " [0.74184394]\n",
      " [0.7418446 ]\n",
      " [0.7418462 ]\n",
      " [0.7418435 ]\n",
      " [0.7418475 ]]\n",
      "실제 레이어 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "실제 값 : 0\n",
      "[[ 0  1]\n",
      " [ 0 24]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 81 samples, validate on 9 samples\n",
      "Epoch 1/10\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 1.2779 - acc: 0.2222 - val_loss: 1.4134 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "81/81 [==============================] - 0s 456us/step - loss: 1.1100 - acc: 0.2222 - val_loss: 1.2025 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "81/81 [==============================] - 0s 452us/step - loss: 0.9672 - acc: 0.2222 - val_loss: 0.9965 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "81/81 [==============================] - 0s 431us/step - loss: 0.8372 - acc: 0.2222 - val_loss: 0.8175 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "81/81 [==============================] - 0s 443us/step - loss: 0.7395 - acc: 0.2346 - val_loss: 0.6669 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "81/81 [==============================] - 0s 296us/step - loss: 0.6585 - acc: 0.7778 - val_loss: 0.5486 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "81/81 [==============================] - 0s 308us/step - loss: 0.6038 - acc: 0.7778 - val_loss: 0.4571 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "81/81 [==============================] - 0s 271us/step - loss: 0.5672 - acc: 0.7778 - val_loss: 0.3887 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "81/81 [==============================] - 0s 283us/step - loss: 0.5480 - acc: 0.7778 - val_loss: 0.3410 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "81/81 [==============================] - 0s 246us/step - loss: 0.5397 - acc: 0.7778 - val_loss: 0.3197 - val_acc: 1.0000\n",
      "6번째 리밸런싱 성공\n",
      "30/30 [==============================] - 0s 33us/step\n",
      "Train,Test의 loss, score : [0.5474066138267517, 0.7666666507720947]\n",
      "1~120영업일까지를 예측 데이터로 121영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.7264127 ]\n",
      " [0.72639465]\n",
      " [0.7264216 ]\n",
      " [0.7264117 ]\n",
      " [0.72641367]\n",
      " [0.7264107 ]\n",
      " [0.72640806]\n",
      " [0.72641957]\n",
      " [0.72640574]\n",
      " [0.72642994]\n",
      " [0.72642636]\n",
      " [0.7264051 ]\n",
      " [0.7264276 ]\n",
      " [0.7264276 ]\n",
      " [0.72642726]\n",
      " [0.7264245 ]\n",
      " [0.7264206 ]\n",
      " [0.72643346]\n",
      " [0.72642565]\n",
      " [0.72641116]\n",
      " [0.72640693]\n",
      " [0.72638977]\n",
      " [0.72639936]\n",
      " [0.7263782 ]\n",
      " [0.7263385 ]\n",
      " [0.72631013]\n",
      " [0.72630465]\n",
      " [0.7262967 ]\n",
      " [0.7263036 ]\n",
      " [0.72632587]]\n",
      "실제 레이어 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      "실제 값 : 0\n",
      "[[ 0  7]\n",
      " [ 0 23]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 94 samples, validate on 11 samples\n",
      "Epoch 1/10\n",
      "94/94 [==============================] - 1s 15ms/step - loss: 0.5553 - acc: 0.8085 - val_loss: 0.3823 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 0s 241us/step - loss: 0.5141 - acc: 0.8085 - val_loss: 0.3041 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 0s 265us/step - loss: 0.4953 - acc: 0.8085 - val_loss: 0.2511 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 0s 254us/step - loss: 0.4890 - acc: 0.8085 - val_loss: 0.2173 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 0s 233us/step - loss: 0.4929 - acc: 0.8085 - val_loss: 0.1929 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 0s 286us/step - loss: 0.4895 - acc: 0.8085 - val_loss: 0.1923 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 0s 329us/step - loss: 0.4895 - acc: 0.8085 - val_loss: 0.1953 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 0s 361us/step - loss: 0.4897 - acc: 0.8085 - val_loss: 0.2030 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 0s 382us/step - loss: 0.4888 - acc: 0.8085 - val_loss: 0.2047 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 0s 424us/step - loss: 0.4890 - acc: 0.8085 - val_loss: 0.2047 - val_acc: 1.0000\n",
      "7번째 리밸런싱 성공\n",
      "35/35 [==============================] - 0s 199us/step\n",
      "Train,Test의 loss, score : [1.2631592341831752, 0.2857142984867096]\n",
      "1~140영업일까지를 예측 데이터로 141영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.81486654]\n",
      " [0.81486535]\n",
      " [0.8148689 ]\n",
      " [0.8148664 ]\n",
      " [0.81486183]\n",
      " [0.81486094]\n",
      " [0.8148557 ]\n",
      " [0.81485873]\n",
      " [0.81485236]\n",
      " [0.814841  ]\n",
      " [0.8148329 ]\n",
      " [0.8148324 ]\n",
      " [0.8148304 ]\n",
      " [0.8148323 ]\n",
      " [0.81483907]\n",
      " [0.8148365 ]\n",
      " [0.8148352 ]\n",
      " [0.8148409 ]\n",
      " [0.81484336]\n",
      " [0.81484044]\n",
      " [0.8148434 ]\n",
      " [0.8148477 ]\n",
      " [0.8148465 ]\n",
      " [0.81484294]\n",
      " [0.8148482 ]\n",
      " [0.814854  ]\n",
      " [0.8148526 ]\n",
      " [0.81484044]\n",
      " [0.81483775]\n",
      " [0.8148345 ]\n",
      " [0.8148305 ]\n",
      " [0.81482756]\n",
      " [0.8148339 ]\n",
      " [0.81482446]\n",
      " [0.81483096]]\n",
      "실제 레이어 : [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "실제 값 : 0\n",
      "[[ 0 25]\n",
      " [ 0 10]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 108 samples, validate on 12 samples\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.0087 - acc: 0.1667 - val_loss: 0.6821 - val_acc: 0.5833\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 0s 397us/step - loss: 0.8219 - acc: 0.1667 - val_loss: 0.6867 - val_acc: 0.5833\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 0s 406us/step - loss: 0.6720 - acc: 0.6111 - val_loss: 0.7253 - val_acc: 0.4167\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 0s 351us/step - loss: 0.5743 - acc: 0.8333 - val_loss: 0.7882 - val_acc: 0.4167\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 0s 378us/step - loss: 0.5128 - acc: 0.8333 - val_loss: 0.8617 - val_acc: 0.4167\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 0s 360us/step - loss: 0.4789 - acc: 0.8333 - val_loss: 0.9347 - val_acc: 0.4167\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 0s 416us/step - loss: 0.4598 - acc: 0.8333 - val_loss: 0.9953 - val_acc: 0.4167\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 0s 365us/step - loss: 0.4571 - acc: 0.8333 - val_loss: 1.0538 - val_acc: 0.4167\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 0s 406us/step - loss: 0.4522 - acc: 0.8333 - val_loss: 1.0905 - val_acc: 0.4167\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 0s 351us/step - loss: 0.4505 - acc: 0.8333 - val_loss: 1.1116 - val_acc: 0.4167\n",
      "8번째 리밸런싱 성공\n",
      "40/40 [==============================] - 0s 149us/step\n",
      "Train,Test의 loss, score : [1.3363664627075196, 0.2750000059604645]\n",
      "1~160영업일까지를 예측 데이터로 161영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.8301143 ]\n",
      " [0.8301109 ]\n",
      " [0.83012354]\n",
      " [0.8301289 ]\n",
      " [0.830122  ]\n",
      " [0.83012855]\n",
      " [0.8301376 ]\n",
      " [0.8301344 ]\n",
      " [0.8301261 ]\n",
      " [0.8301382 ]\n",
      " [0.83015037]\n",
      " [0.83014655]\n",
      " [0.8301202 ]\n",
      " [0.8301146 ]\n",
      " [0.8301084 ]\n",
      " [0.8300994 ]\n",
      " [0.83009386]\n",
      " [0.8301084 ]\n",
      " [0.8300879 ]\n",
      " [0.8301027 ]\n",
      " [0.8301025 ]\n",
      " [0.8301071 ]\n",
      " [0.83011484]\n",
      " [0.8301033 ]\n",
      " [0.830105  ]\n",
      " [0.83011806]\n",
      " [0.8301146 ]\n",
      " [0.8301425 ]\n",
      " [0.83015287]\n",
      " [0.8301561 ]\n",
      " [0.8301567 ]\n",
      " [0.8301528 ]\n",
      " [0.83015543]\n",
      " [0.8301428 ]\n",
      " [0.83010685]\n",
      " [0.8301267 ]\n",
      " [0.830127  ]\n",
      " [0.83013844]\n",
      " [0.8301505 ]\n",
      " [0.8301573 ]]\n",
      "실제 레이어 : [0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1\n",
      " 1 1 0]\n",
      "실제 값 : 0\n",
      "[[ 0 29]\n",
      " [ 0 11]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121 samples, validate on 14 samples\n",
      "Epoch 1/10\n",
      "121/121 [==============================] - 2s 13ms/step - loss: 0.7040 - acc: 0.4711 - val_loss: 0.7861 - val_acc: 0.1429\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 0s 297us/step - loss: 0.6025 - acc: 0.7851 - val_loss: 0.9763 - val_acc: 0.1429\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 0s 280us/step - loss: 0.5469 - acc: 0.7851 - val_loss: 1.1519 - val_acc: 0.1429\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 0s 272us/step - loss: 0.5267 - acc: 0.7851 - val_loss: 1.2764 - val_acc: 0.1429\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 0s 272us/step - loss: 0.5219 - acc: 0.7851 - val_loss: 1.3521 - val_acc: 0.1429\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 0s 255us/step - loss: 0.5205 - acc: 0.7851 - val_loss: 1.3744 - val_acc: 0.1429\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 0s 413us/step - loss: 0.5209 - acc: 0.7851 - val_loss: 1.3862 - val_acc: 0.1429\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 0s 371us/step - loss: 0.5212 - acc: 0.7851 - val_loss: 1.3526 - val_acc: 0.1429\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 0s 412us/step - loss: 0.5208 - acc: 0.7851 - val_loss: 1.3443 - val_acc: 0.1429\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 0s 288us/step - loss: 0.5207 - acc: 0.7851 - val_loss: 1.3403 - val_acc: 0.1429\n",
      "9번째 리밸런싱 성공\n",
      "45/45 [==============================] - 0s 133us/step\n",
      "Train,Test의 loss, score : [0.6998910791344113, 0.644444465637207]\n",
      "1~180영업일까지를 예측 데이터로 181영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.7818265 ]\n",
      " [0.7818183 ]\n",
      " [0.7818335 ]\n",
      " [0.78181446]\n",
      " [0.7818278 ]\n",
      " [0.7818299 ]\n",
      " [0.78183544]\n",
      " [0.78184557]\n",
      " [0.7818333 ]\n",
      " [0.7818334 ]\n",
      " [0.78184915]\n",
      " [0.7818466 ]\n",
      " [0.78188336]\n",
      " [0.7818986 ]\n",
      " [0.7819058 ]\n",
      " [0.7819071 ]\n",
      " [0.78189886]\n",
      " [0.781903  ]\n",
      " [0.7818868 ]\n",
      " [0.7818404 ]\n",
      " [0.78185666]\n",
      " [0.78185976]\n",
      " [0.781875  ]\n",
      " [0.78189373]\n",
      " [0.78190553]\n",
      " [0.7819145 ]\n",
      " [0.7819149 ]\n",
      " [0.7819221 ]\n",
      " [0.7819299 ]\n",
      " [0.78192806]\n",
      " [0.7819328 ]\n",
      " [0.78193253]\n",
      " [0.78193164]\n",
      " [0.7819228 ]\n",
      " [0.7819195 ]\n",
      " [0.7819159 ]\n",
      " [0.78191936]\n",
      " [0.7819208 ]\n",
      " [0.78192675]\n",
      " [0.7819238 ]\n",
      " [0.7819111 ]\n",
      " [0.78191864]\n",
      " [0.7819289 ]\n",
      " [0.78191996]\n",
      " [0.7819309 ]]\n",
      "실제 레이어 : [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0]\n",
      "실제 값 : 0\n",
      "[[ 0 16]\n",
      " [ 0 29]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.6850 - acc: 0.5111 - val_loss: 0.8027 - val_acc: 0.2000\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.6206 - acc: 0.7185 - val_loss: 0.9418 - val_acc: 0.2000\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.5990 - acc: 0.7185 - val_loss: 1.0327 - val_acc: 0.2000\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 415us/step - loss: 0.5940 - acc: 0.7185 - val_loss: 1.0907 - val_acc: 0.2000\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.5945 - acc: 0.7185 - val_loss: 1.1024 - val_acc: 0.2000\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 429us/step - loss: 0.5946 - acc: 0.7185 - val_loss: 1.0918 - val_acc: 0.2000\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.5946 - acc: 0.7185 - val_loss: 1.0851 - val_acc: 0.2000\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 288us/step - loss: 0.5948 - acc: 0.7185 - val_loss: 1.0897 - val_acc: 0.2000\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.5954 - acc: 0.7185 - val_loss: 1.1123 - val_acc: 0.2000\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.5951 - acc: 0.7185 - val_loss: 1.1096 - val_acc: 0.2000\n",
      "10번째 리밸런싱 성공\n",
      "50/50 [==============================] - 0s 80us/step\n",
      "Train,Test의 loss, score : [0.5533070230484008, 0.7599999904632568]\n",
      "1~200영업일까지를 예측 데이터로 201영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.72987384]\n",
      " [0.7298598 ]\n",
      " [0.72986555]\n",
      " [0.72982687]\n",
      " [0.7297333 ]\n",
      " [0.72977597]\n",
      " [0.7297848 ]\n",
      " [0.7298187 ]\n",
      " [0.7298561 ]\n",
      " [0.7298789 ]\n",
      " [0.72989327]\n",
      " [0.7298957 ]\n",
      " [0.7299117 ]\n",
      " [0.72993267]\n",
      " [0.729924  ]\n",
      " [0.72993255]\n",
      " [0.72992855]\n",
      " [0.72992545]\n",
      " [0.72990495]\n",
      " [0.72989213]\n",
      " [0.729886  ]\n",
      " [0.7299042 ]\n",
      " [0.7299023 ]\n",
      " [0.7299126 ]\n",
      " [0.7299062 ]\n",
      " [0.7298726 ]\n",
      " [0.729893  ]\n",
      " [0.7299156 ]\n",
      " [0.7298964 ]\n",
      " [0.7299243 ]\n",
      " [0.7298724 ]\n",
      " [0.7298926 ]\n",
      " [0.72988844]\n",
      " [0.72989696]\n",
      " [0.729825  ]\n",
      " [0.72985196]\n",
      " [0.729888  ]\n",
      " [0.7298968 ]\n",
      " [0.72987694]\n",
      " [0.7299091 ]\n",
      " [0.7299223 ]\n",
      " [0.7298143 ]\n",
      " [0.72977257]\n",
      " [0.72974294]\n",
      " [0.7297159 ]\n",
      " [0.72973835]\n",
      " [0.7296973 ]\n",
      " [0.7297038 ]\n",
      " [0.72968864]\n",
      " [0.72971207]]\n",
      "실제 레이어 : [1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      "실제 값 : 0\n",
      "[[ 0 12]\n",
      " [ 0 38]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 148 samples, validate on 17 samples\n",
      "Epoch 1/10\n",
      "148/148 [==============================] - 2s 12ms/step - loss: 0.8342 - acc: 0.3378 - val_loss: 0.7989 - val_acc: 0.1765\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 0s 270us/step - loss: 0.7093 - acc: 0.4459 - val_loss: 0.6505 - val_acc: 0.8235\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 0s 417us/step - loss: 0.6543 - acc: 0.6622 - val_loss: 0.5745 - val_acc: 0.8235\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 0s 343us/step - loss: 0.6436 - acc: 0.6622 - val_loss: 0.5360 - val_acc: 0.8235\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 0s 270us/step - loss: 0.6411 - acc: 0.6622 - val_loss: 0.5201 - val_acc: 0.8235\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 0s 249us/step - loss: 0.6405 - acc: 0.6622 - val_loss: 0.5265 - val_acc: 0.8235\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 0s 404us/step - loss: 0.6399 - acc: 0.6622 - val_loss: 0.5277 - val_acc: 0.8235\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 0s 431us/step - loss: 0.6399 - acc: 0.6622 - val_loss: 0.5250 - val_acc: 0.8235\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 0s 337us/step - loss: 0.6406 - acc: 0.6622 - val_loss: 0.5271 - val_acc: 0.8235\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 0s 283us/step - loss: 0.6397 - acc: 0.6622 - val_loss: 0.5287 - val_acc: 0.8235\n",
      "11번째 리밸런싱 성공\n",
      "55/55 [==============================] - 0s 92us/step\n",
      "Train,Test의 loss, score : [0.7071960882707076, 0.5636363625526428]\n",
      "1~220영업일까지를 예측 데이터로 221영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.66538095]\n",
      " [0.66538036]\n",
      " [0.6653792 ]\n",
      " [0.66536844]\n",
      " [0.6653602 ]\n",
      " [0.6653554 ]\n",
      " [0.6653624 ]\n",
      " [0.66536194]\n",
      " [0.66536725]\n",
      " [0.66536486]\n",
      " [0.6653473 ]\n",
      " [0.6653561 ]\n",
      " [0.6653689 ]\n",
      " [0.66535974]\n",
      " [0.66537386]\n",
      " [0.665347  ]\n",
      " [0.6653553 ]\n",
      " [0.665353  ]\n",
      " [0.66535765]\n",
      " [0.665318  ]\n",
      " [0.66532725]\n",
      " [0.66534686]\n",
      " [0.6653539 ]\n",
      " [0.6653451 ]\n",
      " [0.6653611 ]\n",
      " [0.6653702 ]\n",
      " [0.665311  ]\n",
      " [0.66527885]\n",
      " [0.665255  ]\n",
      " [0.66523236]\n",
      " [0.66523993]\n",
      " [0.6652163 ]\n",
      " [0.66521555]\n",
      " [0.66520506]\n",
      " [0.6652163 ]\n",
      " [0.6652161 ]\n",
      " [0.6652019 ]\n",
      " [0.66519886]\n",
      " [0.66520697]\n",
      " [0.66520625]\n",
      " [0.66522527]\n",
      " [0.665229  ]\n",
      " [0.6652432 ]\n",
      " [0.66528904]\n",
      " [0.66529465]\n",
      " [0.6652872 ]\n",
      " [0.66533095]\n",
      " [0.6653452 ]\n",
      " [0.66533726]\n",
      " [0.6653091 ]\n",
      " [0.6653098 ]\n",
      " [0.6653329 ]\n",
      " [0.66534436]\n",
      " [0.66534024]\n",
      " [0.66536176]]\n",
      "실제 레이어 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0]\n",
      "실제 값 : 0\n",
      "[[ 0 24]\n",
      " [ 0 31]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 162 samples, validate on 18 samples\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 0.6343 - acc: 0.6728 - val_loss: 0.4063 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 0s 439us/step - loss: 0.6320 - acc: 0.6728 - val_loss: 0.3639 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 549us/step - loss: 0.6338 - acc: 0.6728 - val_loss: 0.3781 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 0s 339us/step - loss: 0.6322 - acc: 0.6728 - val_loss: 0.4075 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 0s 339us/step - loss: 0.6326 - acc: 0.6728 - val_loss: 0.3908 - val_acc: 1.0000\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 289us/step - loss: 0.6340 - acc: 0.6728 - val_loss: 0.3676 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 0s 320us/step - loss: 0.6344 - acc: 0.6728 - val_loss: 0.4154 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 0s 302us/step - loss: 0.6327 - acc: 0.6728 - val_loss: 0.4229 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 0s 296us/step - loss: 0.6330 - acc: 0.6728 - val_loss: 0.3944 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 0s 351us/step - loss: 0.6324 - acc: 0.6728 - val_loss: 0.3984 - val_acc: 1.0000\n",
      "12번째 리밸런싱 성공\n",
      "60/60 [==============================] - 0s 134us/step\n",
      "Train,Test의 loss, score : [0.6839852650960286, 0.6000000238418579]\n",
      "1~240영업일까지를 예측 데이터로 241영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.67135376]\n",
      " [0.67139035]\n",
      " [0.6713803 ]\n",
      " [0.6713939 ]\n",
      " [0.6713    ]\n",
      " [0.6713356 ]\n",
      " [0.6713813 ]\n",
      " [0.67139083]\n",
      " [0.67136526]\n",
      " [0.67138815]\n",
      " [0.67141557]\n",
      " [0.6712694 ]\n",
      " [0.6712245 ]\n",
      " [0.6711861 ]\n",
      " [0.6711637 ]\n",
      " [0.67119265]\n",
      " [0.6711359 ]\n",
      " [0.6711544 ]\n",
      " [0.67113125]\n",
      " [0.6711628 ]\n",
      " [0.67115754]\n",
      " [0.6711166 ]\n",
      " [0.6711237 ]\n",
      " [0.67115027]\n",
      " [0.67114246]\n",
      " [0.67118704]\n",
      " [0.67118335]\n",
      " [0.6712109 ]\n",
      " [0.671298  ]\n",
      " [0.6712909 ]\n",
      " [0.6712626 ]\n",
      " [0.6713725 ]\n",
      " [0.671382  ]\n",
      " [0.67135054]\n",
      " [0.6712878 ]\n",
      " [0.67130804]\n",
      " [0.6713597 ]\n",
      " [0.6713774 ]\n",
      " [0.67136127]\n",
      " [0.671415  ]\n",
      " [0.6714286 ]\n",
      " [0.67143065]\n",
      " [0.6714333 ]\n",
      " [0.6714002 ]\n",
      " [0.6714119 ]\n",
      " [0.67137194]\n",
      " [0.671371  ]\n",
      " [0.671438  ]\n",
      " [0.671397  ]\n",
      " [0.67142737]\n",
      " [0.67138296]\n",
      " [0.67140967]\n",
      " [0.6713897 ]\n",
      " [0.67140734]\n",
      " [0.67142105]\n",
      " [0.67139566]\n",
      " [0.6714101 ]\n",
      " [0.67138   ]\n",
      " [0.6714305 ]\n",
      " [0.6714227 ]]\n",
      "실제 레이어 : [1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "실제 값 : 0\n",
      "[[ 0 24]\n",
      " [ 0 36]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 175 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 0.7437 - acc: 0.3200 - val_loss: 0.6793 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 0s 408us/step - loss: 0.6542 - acc: 0.6971 - val_loss: 0.5770 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 0s 274us/step - loss: 0.6236 - acc: 0.6971 - val_loss: 0.5324 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 0s 279us/step - loss: 0.6161 - acc: 0.6971 - val_loss: 0.5211 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 0s 302us/step - loss: 0.6145 - acc: 0.6971 - val_loss: 0.5221 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 0s 251us/step - loss: 0.6134 - acc: 0.6971 - val_loss: 0.5242 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 0s 245us/step - loss: 0.6143 - acc: 0.6971 - val_loss: 0.5303 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 0s 313us/step - loss: 0.6137 - acc: 0.6971 - val_loss: 0.5275 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 0s 319us/step - loss: 0.6133 - acc: 0.6971 - val_loss: 0.5287 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 0s 342us/step - loss: 0.6134 - acc: 0.6971 - val_loss: 0.5274 - val_acc: 0.8000\n",
      "13번째 리밸런싱 성공\n",
      "65/65 [==============================] - 0s 138us/step\n",
      "Train,Test의 loss, score : [0.6170458298463087, 0.692307710647583]\n",
      "1~260영업일까지를 예측 데이터로 261영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.6968422 ]\n",
      " [0.69677585]\n",
      " [0.69678074]\n",
      " [0.6967546 ]\n",
      " [0.6967901 ]\n",
      " [0.69678724]\n",
      " [0.6967419 ]\n",
      " [0.6967383 ]\n",
      " [0.6967641 ]\n",
      " [0.6967616 ]\n",
      " [0.69681454]\n",
      " [0.69681746]\n",
      " [0.6968533 ]\n",
      " [0.696977  ]\n",
      " [0.6969784 ]\n",
      " [0.69694865]\n",
      " [0.6970718 ]\n",
      " [0.6970986 ]\n",
      " [0.6970682 ]\n",
      " [0.6969903 ]\n",
      " [0.69699854]\n",
      " [0.69706684]\n",
      " [0.69709337]\n",
      " [0.6970775 ]\n",
      " [0.6971361 ]\n",
      " [0.6971563 ]\n",
      " [0.69718206]\n",
      " [0.6971781 ]\n",
      " [0.6971435 ]\n",
      " [0.6971437 ]\n",
      " [0.69709814]\n",
      " [0.6971024 ]\n",
      " [0.6971796 ]\n",
      " [0.69713455]\n",
      " [0.697167  ]\n",
      " [0.6971143 ]\n",
      " [0.697145  ]\n",
      " [0.6971217 ]\n",
      " [0.6971408 ]\n",
      " [0.6971577 ]\n",
      " [0.69712824]\n",
      " [0.6971427 ]\n",
      " [0.6971107 ]\n",
      " [0.69716   ]\n",
      " [0.69716346]\n",
      " [0.69716203]\n",
      " [0.69715613]\n",
      " [0.69715303]\n",
      " [0.6971735 ]\n",
      " [0.6971369 ]\n",
      " [0.6970559 ]\n",
      " [0.69703406]\n",
      " [0.6971355 ]\n",
      " [0.6971429 ]\n",
      " [0.6971035 ]\n",
      " [0.69695354]\n",
      " [0.69700253]\n",
      " [0.6971258 ]\n",
      " [0.6970936 ]\n",
      " [0.6970826 ]\n",
      " [0.69712114]\n",
      " [0.69711494]\n",
      " [0.69704187]\n",
      " [0.6970107 ]\n",
      " [0.697056  ]]\n",
      "실제 레이어 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "실제 값 : 0\n",
      "[[ 0 20]\n",
      " [ 0 45]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 189 samples, validate on 21 samples\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.6012 - acc: 0.7196 - val_loss: 1.2096 - val_acc: 0.0952\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 417us/step - loss: 0.5936 - acc: 0.7196 - val_loss: 1.1768 - val_acc: 0.0952\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 554us/step - loss: 0.5942 - acc: 0.7196 - val_loss: 1.1650 - val_acc: 0.0952\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 306us/step - loss: 0.5938 - acc: 0.7196 - val_loss: 1.1698 - val_acc: 0.0952\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 327us/step - loss: 0.5938 - acc: 0.7196 - val_loss: 1.2007 - val_acc: 0.0952\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 454us/step - loss: 0.5936 - acc: 0.7196 - val_loss: 1.1981 - val_acc: 0.0952\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 377us/step - loss: 0.5952 - acc: 0.7196 - val_loss: 1.1573 - val_acc: 0.0952\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 301us/step - loss: 0.5944 - acc: 0.7196 - val_loss: 1.1974 - val_acc: 0.0952\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 285us/step - loss: 0.5938 - acc: 0.7196 - val_loss: 1.1847 - val_acc: 0.0952\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 396us/step - loss: 0.5940 - acc: 0.7196 - val_loss: 1.1855 - val_acc: 0.0952\n",
      "14번째 리밸런싱 성공\n",
      "70/70 [==============================] - 0s 199us/step\n",
      "Train,Test의 loss, score : [0.6660111733845302, 0.6428571343421936]\n",
      "1~280영업일까지를 예측 데이터로 281영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.72090507]\n",
      " [0.72099125]\n",
      " [0.7210096 ]\n",
      " [0.7209882 ]\n",
      " [0.7209342 ]\n",
      " [0.7209408 ]\n",
      " [0.72098565]\n",
      " [0.7210049 ]\n",
      " [0.72099495]\n",
      " [0.7210377 ]\n",
      " [0.72105277]\n",
      " [0.7210648 ]\n",
      " [0.72106564]\n",
      " [0.72104037]\n",
      " [0.7210441 ]\n",
      " [0.7210121 ]\n",
      " [0.72101045]\n",
      " [0.72106385]\n",
      " [0.7210353 ]\n",
      " [0.72105867]\n",
      " [0.72102356]\n",
      " [0.7210437 ]\n",
      " [0.72102815]\n",
      " [0.72104126]\n",
      " [0.7210535 ]\n",
      " [0.72103393]\n",
      " [0.7210446 ]\n",
      " [0.7210216 ]\n",
      " [0.7210581 ]\n",
      " [0.7210586 ]\n",
      " [0.72105634]\n",
      " [0.72105217]\n",
      " [0.7210503 ]\n",
      " [0.72106606]\n",
      " [0.721038  ]\n",
      " [0.7209816 ]\n",
      " [0.7209665 ]\n",
      " [0.72103524]\n",
      " [0.7210403 ]\n",
      " [0.72101504]\n",
      " [0.72091186]\n",
      " [0.7209398 ]\n",
      " [0.72102463]\n",
      " [0.721003  ]\n",
      " [0.7209976 ]\n",
      " [0.72102606]\n",
      " [0.72102165]\n",
      " [0.7209719 ]\n",
      " [0.7209486 ]\n",
      " [0.72097987]\n",
      " [0.72091067]\n",
      " [0.7208882 ]\n",
      " [0.72083604]\n",
      " [0.720823  ]\n",
      " [0.7208621 ]\n",
      " [0.7208498 ]\n",
      " [0.7208394 ]\n",
      " [0.72088504]\n",
      " [0.7208904 ]\n",
      " [0.7208289 ]\n",
      " [0.72081774]\n",
      " [0.7208138 ]\n",
      " [0.7207809 ]\n",
      " [0.7207854 ]\n",
      " [0.72078115]\n",
      " [0.72080535]\n",
      " [0.7208444 ]\n",
      " [0.7208699 ]\n",
      " [0.72090304]\n",
      " [0.7209011 ]]\n",
      "실제 레이어 : [0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "실제 값 : 0\n",
      "[[ 0 25]\n",
      " [ 0 45]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 202 samples, validate on 23 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 0.8776 - acc: 0.3168 - val_loss: 0.6984 - val_acc: 0.5217\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 449us/step - loss: 0.6969 - acc: 0.5347 - val_loss: 0.7070 - val_acc: 0.4783\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 420us/step - loss: 0.6324 - acc: 0.6832 - val_loss: 0.7602 - val_acc: 0.4783\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 321us/step - loss: 0.6269 - acc: 0.6832 - val_loss: 0.7956 - val_acc: 0.4783\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.6252 - acc: 0.6832 - val_loss: 0.7982 - val_acc: 0.4783\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 321us/step - loss: 0.6252 - acc: 0.6832 - val_loss: 0.7940 - val_acc: 0.4783\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 316us/step - loss: 0.6248 - acc: 0.6832 - val_loss: 0.7825 - val_acc: 0.4783\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 316us/step - loss: 0.6247 - acc: 0.6832 - val_loss: 0.7782 - val_acc: 0.4783\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 355us/step - loss: 0.6247 - acc: 0.6832 - val_loss: 0.7830 - val_acc: 0.4783\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 336us/step - loss: 0.6245 - acc: 0.6832 - val_loss: 0.7794 - val_acc: 0.4783\n",
      "15번째 리밸런싱 성공\n",
      "75/75 [==============================] - 0s 106us/step\n",
      "Train,Test의 loss, score : [0.6366377393404643, 0.6666666865348816]\n",
      "1~300영업일까지를 예측 데이터로 301영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.6810256 ]\n",
      " [0.68102   ]\n",
      " [0.68112296]\n",
      " [0.6810756 ]\n",
      " [0.68111813]\n",
      " [0.6810505 ]\n",
      " [0.6810863 ]\n",
      " [0.68105626]\n",
      " [0.681082  ]\n",
      " [0.68110734]\n",
      " [0.6810704 ]\n",
      " [0.6810875 ]\n",
      " [0.68104374]\n",
      " [0.6811109 ]\n",
      " [0.6811185 ]\n",
      " [0.6811143 ]\n",
      " [0.6811053 ]\n",
      " [0.68110174]\n",
      " [0.6811328 ]\n",
      " [0.6810785 ]\n",
      " [0.68095875]\n",
      " [0.68092257]\n",
      " [0.68106747]\n",
      " [0.6810829 ]\n",
      " [0.68103313]\n",
      " [0.6808126 ]\n",
      " [0.68086267]\n",
      " [0.6810473 ]\n",
      " [0.6810118 ]\n",
      " [0.6809962 ]\n",
      " [0.68105173]\n",
      " [0.6810472 ]\n",
      " [0.68094265]\n",
      " [0.68088734]\n",
      " [0.6809521 ]\n",
      " [0.68080956]\n",
      " [0.6807529 ]\n",
      " [0.6806489 ]\n",
      " [0.68062335]\n",
      " [0.6806869 ]\n",
      " [0.68067366]\n",
      " [0.6806502 ]\n",
      " [0.68074095]\n",
      " [0.68076557]\n",
      " [0.6806402 ]\n",
      " [0.6806003 ]\n",
      " [0.6805951 ]\n",
      " [0.6805255 ]\n",
      " [0.68052375]\n",
      " [0.6805343 ]\n",
      " [0.68056476]\n",
      " [0.6806556 ]\n",
      " [0.68071616]\n",
      " [0.6807904 ]\n",
      " [0.6807956 ]\n",
      " [0.6808924 ]\n",
      " [0.68092394]\n",
      " [0.68088144]\n",
      " [0.68097085]\n",
      " [0.6809851 ]\n",
      " [0.6810117 ]\n",
      " [0.68106973]\n",
      " [0.6810867 ]\n",
      " [0.68109316]\n",
      " [0.6811133 ]\n",
      " [0.6811211 ]\n",
      " [0.6811281 ]\n",
      " [0.68114364]\n",
      " [0.68111813]\n",
      " [0.6810945 ]\n",
      " [0.68112785]\n",
      " [0.68109804]\n",
      " [0.68110347]\n",
      " [0.68100834]\n",
      " [0.68093556]]\n",
      "실제 레이어 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0]\n",
      "실제 값 : 0\n",
      "[[ 0 25]\n",
      " [ 0 50]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 216 samples, validate on 24 samples\n",
      "Epoch 1/10\n",
      "216/216 [==============================] - 3s 12ms/step - loss: 0.6521 - acc: 0.6481 - val_loss: 0.4163 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "216/216 [==============================] - 0s 536us/step - loss: 0.6496 - acc: 0.6481 - val_loss: 0.4438 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "216/216 [==============================] - 0s 452us/step - loss: 0.6489 - acc: 0.6481 - val_loss: 0.4350 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "216/216 [==============================] - 0s 543us/step - loss: 0.6497 - acc: 0.6481 - val_loss: 0.4428 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "216/216 [==============================] - 0s 342us/step - loss: 0.6493 - acc: 0.6481 - val_loss: 0.4236 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "216/216 [==============================] - 0s 332us/step - loss: 0.6492 - acc: 0.6481 - val_loss: 0.4470 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "216/216 [==============================] - 0s 304us/step - loss: 0.6495 - acc: 0.6481 - val_loss: 0.4325 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "216/216 [==============================] - 0s 388us/step - loss: 0.6485 - acc: 0.6481 - val_loss: 0.4385 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "216/216 [==============================] - 0s 328us/step - loss: 0.6500 - acc: 0.6481 - val_loss: 0.4358 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "216/216 [==============================] - 0s 356us/step - loss: 0.6536 - acc: 0.6481 - val_loss: 0.4754 - val_acc: 1.0000\n",
      "16번째 리밸런싱 성공\n",
      "80/80 [==============================] - 0s 125us/step\n",
      "Train,Test의 loss, score : [0.6544090628623962, 0.637499988079071]\n",
      "1~320영업일까지를 예측 데이터로 321영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.62175906]\n",
      " [0.62173   ]\n",
      " [0.62172097]\n",
      " [0.62182695]\n",
      " [0.62163293]\n",
      " [0.6212322 ]\n",
      " [0.6211193 ]\n",
      " [0.6215967 ]\n",
      " [0.62163323]\n",
      " [0.62147915]\n",
      " [0.6207128 ]\n",
      " [0.620866  ]\n",
      " [0.62149656]\n",
      " [0.6213665 ]\n",
      " [0.6213276 ]\n",
      " [0.62152696]\n",
      " [0.6215057 ]\n",
      " [0.6211551 ]\n",
      " [0.62095255]\n",
      " [0.62118495]\n",
      " [0.62067336]\n",
      " [0.6204826 ]\n",
      " [0.6201114 ]\n",
      " [0.6200353 ]\n",
      " [0.6202687 ]\n",
      " [0.62019444]\n",
      " [0.6201171 ]\n",
      " [0.6204404 ]\n",
      " [0.62051153]\n",
      " [0.6200894 ]\n",
      " [0.6199523 ]\n",
      " [0.61995935]\n",
      " [0.61974615]\n",
      " [0.61976516]\n",
      " [0.6197741 ]\n",
      " [0.6198962 ]\n",
      " [0.62018794]\n",
      " [0.62039614]\n",
      " [0.6206568 ]\n",
      " [0.6206683 ]\n",
      " [0.6210206 ]\n",
      " [0.621127  ]\n",
      " [0.620983  ]\n",
      " [0.6213088 ]\n",
      " [0.6213487 ]\n",
      " [0.62144506]\n",
      " [0.62163156]\n",
      " [0.6216817 ]\n",
      " [0.6217048 ]\n",
      " [0.6217694 ]\n",
      " [0.62179226]\n",
      " [0.6218289 ]\n",
      " [0.6218646 ]\n",
      " [0.62177086]\n",
      " [0.6217016 ]\n",
      " [0.62182194]\n",
      " [0.621721  ]\n",
      " [0.6217344 ]\n",
      " [0.62140536]\n",
      " [0.6211716 ]\n",
      " [0.62069035]\n",
      " [0.62022614]\n",
      " [0.62010765]\n",
      " [0.6203098 ]\n",
      " [0.6201519 ]\n",
      " [0.6204779 ]\n",
      " [0.62093824]\n",
      " [0.6212546 ]\n",
      " [0.6212884 ]\n",
      " [0.6215224 ]\n",
      " [0.6214981 ]\n",
      " [0.6213881 ]\n",
      " [0.6212995 ]\n",
      " [0.62133807]\n",
      " [0.6214798 ]\n",
      " [0.62133914]\n",
      " [0.6216032 ]\n",
      " [0.62166196]\n",
      " [0.62163335]\n",
      " [0.6216905 ]]\n",
      "실제 레이어 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0]\n",
      "실제 값 : 0\n",
      "[[ 0 29]\n",
      " [ 0 51]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 229 samples, validate on 26 samples\n",
      "Epoch 1/10\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.8168 - acc: 0.3319 - val_loss: 0.7305 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "229/229 [==============================] - 0s 695us/step - loss: 0.6722 - acc: 0.6332 - val_loss: 0.4767 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "229/229 [==============================] - 0s 466us/step - loss: 0.6356 - acc: 0.6681 - val_loss: 0.4120 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "229/229 [==============================] - 0s 318us/step - loss: 0.6366 - acc: 0.6681 - val_loss: 0.3787 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "229/229 [==============================] - 0s 329us/step - loss: 0.6361 - acc: 0.6681 - val_loss: 0.3899 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "229/229 [==============================] - 0s 327us/step - loss: 0.6354 - acc: 0.6681 - val_loss: 0.4142 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "229/229 [==============================] - 0s 335us/step - loss: 0.6361 - acc: 0.6681 - val_loss: 0.4044 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "229/229 [==============================] - 0s 349us/step - loss: 0.6358 - acc: 0.6681 - val_loss: 0.4047 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6375 - acc: 0.6681 - val_loss: 0.4205 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "229/229 [==============================] - 0s 466us/step - loss: 0.6391 - acc: 0.6681 - val_loss: 0.3722 - val_acc: 1.0000\n",
      "17번째 리밸런싱 성공\n",
      "85/85 [==============================] - 0s 129us/step\n",
      "Train,Test의 loss, score : [0.6995321217705222, 0.5882353186607361]\n",
      "1~340영업일까지를 예측 데이터로 341영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.68921137]\n",
      " [0.6891929 ]\n",
      " [0.6890343 ]\n",
      " [0.68896276]\n",
      " [0.68906724]\n",
      " [0.68882674]\n",
      " [0.6887548 ]\n",
      " [0.68857026]\n",
      " [0.68853104]\n",
      " [0.6886893 ]\n",
      " [0.6886295 ]\n",
      " [0.6885948 ]\n",
      " [0.68876517]\n",
      " [0.6887722 ]\n",
      " [0.6885407 ]\n",
      " [0.6885259 ]\n",
      " [0.6885115 ]\n",
      " [0.6883839 ]\n",
      " [0.6884155 ]\n",
      " [0.68839574]\n",
      " [0.6885064 ]\n",
      " [0.6886416 ]\n",
      " [0.68871635]\n",
      " [0.6888296 ]\n",
      " [0.68881166]\n",
      " [0.68899673]\n",
      " [0.6890149 ]\n",
      " [0.6889354 ]\n",
      " [0.68910134]\n",
      " [0.6891099 ]\n",
      " [0.68915683]\n",
      " [0.68925595]\n",
      " [0.6892722 ]\n",
      " [0.6892695 ]\n",
      " [0.68931097]\n",
      " [0.68931186]\n",
      " [0.68932074]\n",
      " [0.6893605 ]\n",
      " [0.6893003 ]\n",
      " [0.6892685 ]\n",
      " [0.6893253 ]\n",
      " [0.68926644]\n",
      " [0.68928456]\n",
      " [0.68913114]\n",
      " [0.6890383 ]\n",
      " [0.68882954]\n",
      " [0.68862534]\n",
      " [0.6885883 ]\n",
      " [0.6886777 ]\n",
      " [0.6885901 ]\n",
      " [0.68875986]\n",
      " [0.6889735 ]\n",
      " [0.68907875]\n",
      " [0.6890969 ]\n",
      " [0.6892257 ]\n",
      " [0.68918014]\n",
      " [0.68912894]\n",
      " [0.6890849 ]\n",
      " [0.6891122 ]\n",
      " [0.6891842 ]\n",
      " [0.68911177]\n",
      " [0.68924266]\n",
      " [0.6892541 ]\n",
      " [0.68924   ]\n",
      " [0.6892642 ]\n",
      " [0.68925065]\n",
      " [0.6891261 ]\n",
      " [0.6892798 ]\n",
      " [0.6892615 ]\n",
      " [0.68924856]\n",
      " [0.68920475]\n",
      " [0.6892002 ]\n",
      " [0.6892295 ]\n",
      " [0.68913734]\n",
      " [0.6889101 ]\n",
      " [0.68857545]\n",
      " [0.68871075]\n",
      " [0.6886523 ]\n",
      " [0.6887536 ]\n",
      " [0.68879855]\n",
      " [0.68895924]\n",
      " [0.68896   ]\n",
      " [0.68892246]\n",
      " [0.6888897 ]\n",
      " [0.68865174]]\n",
      "실제 레이어 : [1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 1 1 1 1 0 0 0]\n",
      "실제 값 : 0\n",
      "[[ 0 35]\n",
      " [ 0 50]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 243 samples, validate on 27 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 3s 10ms/step - loss: 0.6593 - acc: 0.6132 - val_loss: 0.6817 - val_acc: 0.5926\n",
      "Epoch 2/10\n",
      "243/243 [==============================] - 0s 456us/step - loss: 0.6226 - acc: 0.6872 - val_loss: 0.7021 - val_acc: 0.5926\n",
      "Epoch 3/10\n",
      "243/243 [==============================] - 0s 415us/step - loss: 0.6213 - acc: 0.6872 - val_loss: 0.6970 - val_acc: 0.5926\n",
      "Epoch 4/10\n",
      "243/243 [==============================] - 0s 394us/step - loss: 0.6213 - acc: 0.6872 - val_loss: 0.6902 - val_acc: 0.5926\n",
      "Epoch 5/10\n",
      "243/243 [==============================] - 0s 571us/step - loss: 0.6231 - acc: 0.6872 - val_loss: 0.6846 - val_acc: 0.5926\n",
      "Epoch 6/10\n",
      "243/243 [==============================] - 0s 443us/step - loss: 0.6239 - acc: 0.6872 - val_loss: 0.6900 - val_acc: 0.5926\n",
      "Epoch 7/10\n",
      "243/243 [==============================] - 0s 421us/step - loss: 0.6231 - acc: 0.6872 - val_loss: 0.6900 - val_acc: 0.5926\n",
      "Epoch 8/10\n",
      "243/243 [==============================] - 0s 488us/step - loss: 0.6211 - acc: 0.6872 - val_loss: 0.6975 - val_acc: 0.5926\n",
      "Epoch 9/10\n",
      "243/243 [==============================] - 0s 468us/step - loss: 0.6247 - acc: 0.6872 - val_loss: 0.6899 - val_acc: 0.5926\n",
      "Epoch 10/10\n",
      "243/243 [==============================] - 0s 390us/step - loss: 0.6240 - acc: 0.6872 - val_loss: 0.7081 - val_acc: 0.5926\n",
      "18번째 리밸런싱 성공\n",
      "90/90 [==============================] - 0s 133us/step\n",
      "Train,Test의 loss, score : [0.6207313590579563, 0.6888889074325562]\n",
      "1~360영업일까지를 예측 데이터로 361영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.7120607 ]\n",
      " [0.7120548 ]\n",
      " [0.7119075 ]\n",
      " [0.71190476]\n",
      " [0.7119281 ]\n",
      " [0.7119889 ]\n",
      " [0.7121796 ]\n",
      " [0.7123114 ]\n",
      " [0.7124711 ]\n",
      " [0.7124869 ]\n",
      " [0.71268594]\n",
      " [0.71275544]\n",
      " [0.71267533]\n",
      " [0.7128523 ]\n",
      " [0.71288264]\n",
      " [0.71293455]\n",
      " [0.71304137]\n",
      " [0.71307373]\n",
      " [0.7130884 ]\n",
      " [0.7131238 ]\n",
      " [0.71313936]\n",
      " [0.7131541 ]\n",
      " [0.7131778 ]\n",
      " [0.713135  ]\n",
      " [0.7130933 ]\n",
      " [0.7131522 ]\n",
      " [0.71310115]\n",
      " [0.7131093 ]\n",
      " [0.71293265]\n",
      " [0.7127902 ]\n",
      " [0.71250516]\n",
      " [0.7122206 ]\n",
      " [0.71214134]\n",
      " [0.7122659 ]\n",
      " [0.7121731 ]\n",
      " [0.7123711 ]\n",
      " [0.7126643 ]\n",
      " [0.71284306]\n",
      " [0.712872  ]\n",
      " [0.7130101 ]\n",
      " [0.712992  ]\n",
      " [0.7129289 ]\n",
      " [0.7128677 ]\n",
      " [0.71288925]\n",
      " [0.7129747 ]\n",
      " [0.7129041 ]\n",
      " [0.7130419 ]\n",
      " [0.71307564]\n",
      " [0.7130661 ]\n",
      " [0.7130937 ]\n",
      " [0.7130824 ]\n",
      " [0.71292436]\n",
      " [0.71309626]\n",
      " [0.71308845]\n",
      " [0.7130821 ]\n",
      " [0.7130288 ]\n",
      " [0.713017  ]\n",
      " [0.71305406]\n",
      " [0.7129492 ]\n",
      " [0.71264815]\n",
      " [0.712197  ]\n",
      " [0.7123093 ]\n",
      " [0.71226895]\n",
      " [0.71238375]\n",
      " [0.71246475]\n",
      " [0.71268237]\n",
      " [0.71270955]\n",
      " [0.7126634 ]\n",
      " [0.71260583]\n",
      " [0.71229947]\n",
      " [0.7121582 ]\n",
      " [0.71207345]\n",
      " [0.71236634]\n",
      " [0.71224535]\n",
      " [0.7125144 ]\n",
      " [0.712707  ]\n",
      " [0.7128354 ]\n",
      " [0.71298045]\n",
      " [0.71297324]\n",
      " [0.7129191 ]\n",
      " [0.71297634]\n",
      " [0.7130541 ]\n",
      " [0.7131257 ]\n",
      " [0.7130768 ]\n",
      " [0.713129  ]\n",
      " [0.7130619 ]\n",
      " [0.7131428 ]\n",
      " [0.71314704]\n",
      " [0.7131722 ]\n",
      " [0.7131896 ]]\n",
      "실제 레이어 : [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "실제 값 : 0\n",
      "[[ 0 28]\n",
      " [ 0 62]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 256 samples, validate on 29 samples\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.6227 - acc: 0.7031 - val_loss: 1.0180 - val_acc: 0.1724\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 0s 483us/step - loss: 0.6069 - acc: 0.7031 - val_loss: 1.1237 - val_acc: 0.1724\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 0s 385us/step - loss: 0.6123 - acc: 0.7031 - val_loss: 1.1147 - val_acc: 0.1724\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 0s 606us/step - loss: 0.6111 - acc: 0.7031 - val_loss: 1.0507 - val_acc: 0.1724\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 0s 460us/step - loss: 0.6085 - acc: 0.7031 - val_loss: 1.0480 - val_acc: 0.1724\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 0s 413us/step - loss: 0.6091 - acc: 0.7031 - val_loss: 1.0855 - val_acc: 0.1724\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 0s 468us/step - loss: 0.6079 - acc: 0.7031 - val_loss: 1.0520 - val_acc: 0.1724\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 0s 452us/step - loss: 0.6098 - acc: 0.7031 - val_loss: 1.0574 - val_acc: 0.1724\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 0s 421us/step - loss: 0.6083 - acc: 0.7031 - val_loss: 1.0743 - val_acc: 0.1724\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 0s 390us/step - loss: 0.6089 - acc: 0.7031 - val_loss: 1.0313 - val_acc: 0.1724\n",
      "19번째 리밸런싱 성공\n",
      "95/95 [==============================] - 0s 148us/step\n",
      "Train,Test의 loss, score : [0.5041234675206636, 0.8315789699554443]\n",
      "1~380영업일까지를 예측 데이터로 381영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.69129837]\n",
      " [0.69159776]\n",
      " [0.69167614]\n",
      " [0.6917081 ]\n",
      " [0.6918059 ]\n",
      " [0.69183993]\n",
      " [0.69187784]\n",
      " [0.6919435 ]\n",
      " [0.6918185 ]\n",
      " [0.6917097 ]\n",
      " [0.69187117]\n",
      " [0.69172657]\n",
      " [0.6917516 ]\n",
      " [0.69126153]\n",
      " [0.6908645 ]\n",
      " [0.69000787]\n",
      " [0.6891321 ]\n",
      " [0.6888933 ]\n",
      " [0.6892818 ]\n",
      " [0.6889846 ]\n",
      " [0.68959177]\n",
      " [0.6904948 ]\n",
      " [0.6910026 ]\n",
      " [0.691079  ]\n",
      " [0.69147635]\n",
      " [0.6914106 ]\n",
      " [0.69123375]\n",
      " [0.69106466]\n",
      " [0.69113004]\n",
      " [0.69137216]\n",
      " [0.6911631 ]\n",
      " [0.6915604 ]\n",
      " [0.69164157]\n",
      " [0.69160926]\n",
      " [0.691686  ]\n",
      " [0.6916517 ]\n",
      " [0.6912102 ]\n",
      " [0.6916983 ]\n",
      " [0.6916644 ]\n",
      " [0.6916438 ]\n",
      " [0.69149446]\n",
      " [0.6914635 ]\n",
      " [0.6915642 ]\n",
      " [0.6912602 ]\n",
      " [0.6903712 ]\n",
      " [0.6889933 ]\n",
      " [0.6893415 ]\n",
      " [0.6892135 ]\n",
      " [0.6895697 ]\n",
      " [0.68980724]\n",
      " [0.69047624]\n",
      " [0.6905473 ]\n",
      " [0.69040287]\n",
      " [0.6902367 ]\n",
      " [0.68929005]\n",
      " [0.68885857]\n",
      " [0.68860316]\n",
      " [0.68950295]\n",
      " [0.6891205 ]\n",
      " [0.6899622 ]\n",
      " [0.69054115]\n",
      " [0.69092095]\n",
      " [0.69134325]\n",
      " [0.6913149 ]\n",
      " [0.6911642 ]\n",
      " [0.6913348 ]\n",
      " [0.6915529 ]\n",
      " [0.69174397]\n",
      " [0.6916004 ]\n",
      " [0.69174653]\n",
      " [0.6915543 ]\n",
      " [0.6917843 ]\n",
      " [0.69178766]\n",
      " [0.6918554 ]\n",
      " [0.6918955 ]\n",
      " [0.69177556]\n",
      " [0.69177306]\n",
      " [0.69186264]\n",
      " [0.69178396]\n",
      " [0.6917329 ]\n",
      " [0.69165397]\n",
      " [0.6918307 ]\n",
      " [0.69176656]\n",
      " [0.6916812 ]\n",
      " [0.6914425 ]\n",
      " [0.69083613]\n",
      " [0.6907995 ]\n",
      " [0.6913127 ]\n",
      " [0.691342  ]\n",
      " [0.69020605]\n",
      " [0.68879926]\n",
      " [0.6896055 ]\n",
      " [0.6897303 ]\n",
      " [0.69058263]\n",
      " [0.6911209 ]]\n",
      "실제 레이어 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0]\n",
      "실제 값 : 0\n",
      "[[ 0 16]\n",
      " [ 0 79]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n",
      "Train on 270 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "270/270 [==============================] - 3s 10ms/step - loss: 0.6303 - acc: 0.6778 - val_loss: 0.7116 - val_acc: 0.5667\n",
      "Epoch 2/10\n",
      "270/270 [==============================] - 0s 469us/step - loss: 0.6305 - acc: 0.6778 - val_loss: 0.7171 - val_acc: 0.5667\n",
      "Epoch 3/10\n",
      "270/270 [==============================] - 0s 480us/step - loss: 0.6289 - acc: 0.6778 - val_loss: 0.7092 - val_acc: 0.5667\n",
      "Epoch 4/10\n",
      "270/270 [==============================] - 0s 465us/step - loss: 0.6292 - acc: 0.6778 - val_loss: 0.7086 - val_acc: 0.5667\n",
      "Epoch 5/10\n",
      "270/270 [==============================] - 0s 495us/step - loss: 0.6315 - acc: 0.6778 - val_loss: 0.7123 - val_acc: 0.5667\n",
      "Epoch 6/10\n",
      "270/270 [==============================] - 0s 410us/step - loss: 0.6294 - acc: 0.6778 - val_loss: 0.7023 - val_acc: 0.5667\n",
      "Epoch 7/10\n",
      "270/270 [==============================] - 0s 462us/step - loss: 0.6310 - acc: 0.6778 - val_loss: 0.7180 - val_acc: 0.5667\n",
      "Epoch 8/10\n",
      "270/270 [==============================] - 0s 521us/step - loss: 0.6307 - acc: 0.6778 - val_loss: 0.7034 - val_acc: 0.5667\n",
      "Epoch 9/10\n",
      "270/270 [==============================] - 0s 436us/step - loss: 0.6284 - acc: 0.6778 - val_loss: 0.7113 - val_acc: 0.5667\n",
      "Epoch 10/10\n",
      "270/270 [==============================] - 0s 362us/step - loss: 0.6281 - acc: 0.6778 - val_loss: 0.7155 - val_acc: 0.5667\n",
      "20번째 리밸런싱 성공\n",
      "100/100 [==============================] - 0s 130us/step\n",
      "Train,Test의 loss, score : [0.5228604435920715, 0.8100000023841858]\n",
      "1~400영업일까지를 예측 데이터로 401영업일은 상승 예측\n",
      "딥러닝이 예측한 값들 : [[0.6887103 ]\n",
      " [0.6881223 ]\n",
      " [0.6879464 ]\n",
      " [0.6881716 ]\n",
      " [0.68796885]\n",
      " [0.68836254]\n",
      " [0.6889216 ]\n",
      " [0.68929136]\n",
      " [0.68934894]\n",
      " [0.6896079 ]\n",
      " [0.68958825]\n",
      " [0.689481  ]\n",
      " [0.6893913 ]\n",
      " [0.6894289 ]\n",
      " [0.6895731 ]\n",
      " [0.68942976]\n",
      " [0.6896997 ]\n",
      " [0.6897602 ]\n",
      " [0.68973553]\n",
      " [0.6897932 ]\n",
      " [0.6897691 ]\n",
      " [0.6894809 ]\n",
      " [0.6897998 ]\n",
      " [0.6897745 ]\n",
      " [0.68976265]\n",
      " [0.68966645]\n",
      " [0.68964773]\n",
      " [0.68971825]\n",
      " [0.68951845]\n",
      " [0.6889274 ]\n",
      " [0.6880313 ]\n",
      " [0.68825495]\n",
      " [0.6881328 ]\n",
      " [0.6883301 ]\n",
      " [0.68849075]\n",
      " [0.6889386 ]\n",
      " [0.68899125]\n",
      " [0.6889128 ]\n",
      " [0.68879855]\n",
      " [0.6881964 ]\n",
      " [0.687925  ]\n",
      " [0.6877608 ]\n",
      " [0.6883176 ]\n",
      " [0.68805385]\n",
      " [0.6886029 ]\n",
      " [0.6889864 ]\n",
      " [0.6892484 ]\n",
      " [0.6895398 ]\n",
      " [0.6895336 ]\n",
      " [0.6894434 ]\n",
      " [0.6895507 ]\n",
      " [0.6896997 ]\n",
      " [0.68981975]\n",
      " [0.6897266 ]\n",
      " [0.68983114]\n",
      " [0.68970555]\n",
      " [0.6898611 ]\n",
      " [0.6898722 ]\n",
      " [0.68991506]\n",
      " [0.6899285 ]\n",
      " [0.6898506 ]\n",
      " [0.68985045]\n",
      " [0.68990636]\n",
      " [0.6898544 ]\n",
      " [0.6898162 ]\n",
      " [0.68977016]\n",
      " [0.68988025]\n",
      " [0.68983245]\n",
      " [0.6897812 ]\n",
      " [0.6896286 ]\n",
      " [0.68923384]\n",
      " [0.6892073 ]\n",
      " [0.6895223 ]\n",
      " [0.68953997]\n",
      " [0.6887976 ]\n",
      " [0.6878797 ]\n",
      " [0.6883704 ]\n",
      " [0.6884254 ]\n",
      " [0.6889987 ]\n",
      " [0.6893557 ]\n",
      " [0.6895528 ]\n",
      " [0.6894357 ]\n",
      " [0.6894387 ]\n",
      " [0.6889787 ]\n",
      " [0.6894741 ]\n",
      " [0.68955874]\n",
      " [0.68963736]\n",
      " [0.68972194]\n",
      " [0.68951327]\n",
      " [0.68951154]\n",
      " [0.68954515]\n",
      " [0.6897636 ]\n",
      " [0.68883365]\n",
      " [0.6886069 ]\n",
      " [0.68840444]\n",
      " [0.6879829 ]\n",
      " [0.6877805 ]\n",
      " [0.6881893 ]\n",
      " [0.6884662 ]\n",
      " [0.68863803]]\n",
      "실제 레이어 : [0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0]\n",
      "실제 값 : 0\n",
      "[[ 0 19]\n",
      " [ 0 81]]\n",
      "□□□예측 실패□□□\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a6919faf6e2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmetrics_updates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train_function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m                     **self._function_kwargs)\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m   3004\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3005\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_tf_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3006\u001b[1;33m         \u001b[0mv1_variable_initialization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3007\u001b[0m     return tf_keras_backend.function(inputs, outputs,\n\u001b[0;32m   3008\u001b[0m                                      \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mv1_variable_initialization\u001b[1;34m()\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mv1_variable_initialization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;34m'`get_session` is not available when '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             'TensorFlow is executing eagerly.')\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_keras_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m(op_input_list)\u001b[0m\n\u001b[0;32m    484\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m       \u001b[0m_initialize_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[1;34m(session)\u001b[0m\n\u001b[0;32m    901\u001b[0m     \u001b[1;31m# marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m     is_initialized = session.run(\n\u001b[1;32m--> 903\u001b[1;33m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    904\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1346\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1350\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1388\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m   \u001b[1;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ------------------------------------------ 실제\n",
    "\n",
    "\n",
    "TF = 25 # 고정값\n",
    "\n",
    "cycle = 20 #고정값\n",
    "\n",
    "VA = 0 #초기값 0\n",
    "DE = 25 #초기값 25\n",
    "NUM = 1 # 초기값 1, 매 차례마다 +1\n",
    "for x in range(10000):\n",
    "    df=index_dic[\"KS11\"]\n",
    "    MA_26=df[\"Close\"].rolling(26).mean().dropna()\n",
    "    y=np.where(df[\"Close\"][TF:DE+cycle].shift(-1)>MA_26[0:VA+cycle].shift(-1),1,0)\n",
    "\n",
    "    df = df.values\n",
    "    df.astype('float32')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df = scaler.fit_transform(df)\n",
    "    X=df[TF:DE+cycle]\n",
    "\n",
    "\n",
    "    train_size = int(15*NUM)\n",
    "    X_train2 = X[:train_size]\n",
    "    X_test2 = X[train_size:] \n",
    "    y_train2 = y[:train_size]\n",
    "    y_test2 = y[train_size:]\n",
    "\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    X_train = np.reshape(X_train2, (X_train2.shape[0], 1, X_train2.shape[1]))\n",
    "    X_test = np.reshape(X_test2, (X_test2.shape[0], 1, X_test2.shape[1]))\n",
    "    y_train=y_train2\n",
    "    y_test=y_test2\n",
    "\n",
    "    # simple lstm network learning\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(36, input_shape=(1, 12)))\n",
    "    for i in range(5):\n",
    "        model.add(Dense(36,activation='sigmoid'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=16,validation_split=0.1)\n",
    "\n",
    "\n",
    "    print(\"{}번째 리밸런싱 성공\".format(NUM))\n",
    "    print(\"Train,Test의 loss, score :\", model.evaluate(X_test,y_test))\n",
    "    \n",
    "    if(model.predict(X_test)[-1]>0.5):\n",
    "        answer=1\n",
    "        print(\"1~{}영업일까지를 예측 데이터로 {}영업일은 상승 예측\".format(NUM*cycle,NUM*cycle+1))\n",
    "    else:\n",
    "        answer=0\n",
    "        print(\"1~{}영업일까지를 예측 데이터로 {}영업일은 하락 예측\".format(NUM*cycle,NUM*cycle+1))\n",
    "    print(\"딥러닝이 예측한 값들 :\",model.predict(X_test))\n",
    "    print(\"실제 레이어 :\",y_test)\n",
    "    print(\"실제 값 :\", y_test[-1] )\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test,np.where(model.predict(X_test)>0.5,1,0)))\n",
    "\n",
    "    if (answer==y_test[-1]):\n",
    "          print(\"■■■예측 성공■■■\")\n",
    "    else:\n",
    "          print(\"□□□예측 실패□□□\")\n",
    "    DE=DE+cycle\n",
    "    VA=VA+cycle\n",
    "    NUM=NUM+1\n",
    "\n",
    "\n",
    "    if (train_size>=int(len(df)*0.75)):\n",
    "        print(\"끝까지 도달했습니다\")\n",
    "        break\n",
    "        \n",
    "    print(\"------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1526 samples, validate on 170 samples\n",
      "Epoch 1/10\n",
      "1526/1526 [==============================] - 47s 31ms/step - loss: 0.6833 - acc: 0.5701 - val_loss: 0.8091 - val_acc: 0.3765\n",
      "Epoch 2/10\n",
      "1526/1526 [==============================] - 3s 2ms/step - loss: 0.6767 - acc: 0.5885 - val_loss: 0.7276 - val_acc: 0.3765oss: 0\n",
      "Epoch 3/10\n",
      "1526/1526 [==============================] - 3s 2ms/step - loss: 0.5848 - acc: 0.7123 - val_loss: 0.4683 - val_acc: 0.8412\n",
      "Epoch 4/10\n",
      "1526/1526 [==============================] - 3s 2ms/step - loss: 0.3963 - acc: 0.8512 - val_loss: 0.4475 - val_acc: 0.8176\n",
      "Epoch 5/10\n",
      "1526/1526 [==============================] - 3s 2ms/step - loss: 0.3837 - acc: 0.8552 - val_loss: 0.4195 - val_acc: 0.8412\n",
      "Epoch 6/10\n",
      "1526/1526 [==============================] - 3s 2ms/step - loss: 0.3625 - acc: 0.8585 - val_loss: 0.3951 - val_acc: 0.8471\n",
      "Epoch 7/10\n",
      "1526/1526 [==============================] - 3s 2ms/step - loss: 0.3421 - acc: 0.8565 - val_loss: 0.5219 - val_acc: 0.7706\n",
      "Epoch 8/10\n",
      "1526/1526 [==============================] - 3s 2ms/step - loss: 0.3473 - acc: 0.8617 - val_loss: 0.4558 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "1526/1526 [==============================] - 3s 2ms/step - loss: 0.3338 - acc: 0.8624 - val_loss: 0.4418 - val_acc: 0.8176\n",
      "Epoch 10/10\n",
      "1526/1526 [==============================] - 3s 2ms/step - loss: 0.3252 - acc: 0.8624 - val_loss: 0.5701 - val_acc: 0.7588\n",
      "1번째 리밸런싱 성공\n",
      "702/702 [==============================] - 1s 770us/step\n",
      "Train,Test의 loss, score : [0.382232592825876, 0.8404558300971985]\n",
      "1~20영업일까지를 예측 데이터로 21영업일은 하락 예측\n",
      "딥러닝이 예측한 값들 : [[0.9584755 ]\n",
      " [0.9609843 ]\n",
      " [0.9610164 ]\n",
      " [0.9613879 ]\n",
      " [0.96314454]\n",
      " [0.96384186]\n",
      " [0.9635472 ]\n",
      " [0.96553737]\n",
      " [0.96585536]\n",
      " [0.965867  ]\n",
      " [0.96573496]\n",
      " [0.9635643 ]\n",
      " [0.9642112 ]\n",
      " [0.96481705]\n",
      " [0.9650966 ]\n",
      " [0.96340513]\n",
      " [0.9623909 ]\n",
      " [0.963334  ]\n",
      " [0.9635807 ]\n",
      " [0.96401584]\n",
      " [0.963081  ]\n",
      " [0.9641719 ]\n",
      " [0.96381336]\n",
      " [0.9603268 ]\n",
      " [0.95755506]\n",
      " [0.95506346]\n",
      " [0.9616585 ]\n",
      " [0.9621595 ]\n",
      " [0.95560116]\n",
      " [0.56090915]\n",
      " [0.53992033]\n",
      " [0.14598715]\n",
      " [0.17894736]\n",
      " [0.17711979]\n",
      " [0.19035372]\n",
      " [0.17188424]\n",
      " [0.402069  ]\n",
      " [0.94902205]\n",
      " [0.9573365 ]\n",
      " [0.9581295 ]\n",
      " [0.96009064]\n",
      " [0.9560533 ]\n",
      " [0.964015  ]\n",
      " [0.96265525]\n",
      " [0.96291703]\n",
      " [0.96438974]\n",
      " [0.9637041 ]\n",
      " [0.9571438 ]\n",
      " [0.94549054]\n",
      " [0.6755557 ]\n",
      " [0.5998067 ]\n",
      " [0.18075827]\n",
      " [0.11953682]\n",
      " [0.18312654]\n",
      " [0.1541383 ]\n",
      " [0.13175055]\n",
      " [0.09665993]\n",
      " [0.09526378]\n",
      " [0.09195727]\n",
      " [0.091883  ]\n",
      " [0.08743662]\n",
      " [0.08919668]\n",
      " [0.10366747]\n",
      " [0.08459285]\n",
      " [0.13972929]\n",
      " [0.14729685]\n",
      " [0.49852318]\n",
      " [0.5929875 ]\n",
      " [0.9375847 ]\n",
      " [0.95444775]\n",
      " [0.96033275]\n",
      " [0.9609884 ]\n",
      " [0.9647422 ]\n",
      " [0.96544456]\n",
      " [0.96398205]\n",
      " [0.9628339 ]\n",
      " [0.9229504 ]\n",
      " [0.8239231 ]\n",
      " [0.38950408]\n",
      " [0.14209902]\n",
      " [0.11493075]\n",
      " [0.2426377 ]\n",
      " [0.25157848]\n",
      " [0.5166939 ]\n",
      " [0.45163354]\n",
      " [0.14654198]\n",
      " [0.1628277 ]\n",
      " [0.18538797]\n",
      " [0.32107615]\n",
      " [0.6997855 ]\n",
      " [0.9381335 ]\n",
      " [0.9561397 ]\n",
      " [0.9585929 ]\n",
      " [0.92435455]\n",
      " [0.9526006 ]\n",
      " [0.9420794 ]\n",
      " [0.9599458 ]\n",
      " [0.96154976]\n",
      " [0.96356946]\n",
      " [0.9646027 ]\n",
      " [0.9650217 ]\n",
      " [0.96579117]\n",
      " [0.9651668 ]\n",
      " [0.9649577 ]\n",
      " [0.96411115]\n",
      " [0.96346664]\n",
      " [0.9636531 ]\n",
      " [0.96581125]\n",
      " [0.9649936 ]\n",
      " [0.96424603]\n",
      " [0.9604286 ]\n",
      " [0.96494097]\n",
      " [0.95581245]\n",
      " [0.33852923]\n",
      " [0.30104864]\n",
      " [0.88497066]\n",
      " [0.9578353 ]\n",
      " [0.96064687]\n",
      " [0.9619271 ]\n",
      " [0.9645475 ]\n",
      " [0.9627173 ]\n",
      " [0.96092063]\n",
      " [0.95797086]\n",
      " [0.96296763]\n",
      " [0.9634458 ]\n",
      " [0.9573462 ]\n",
      " [0.96081793]\n",
      " [0.957181  ]\n",
      " [0.9551176 ]\n",
      " [0.937752  ]\n",
      " [0.71104646]\n",
      " [0.67466694]\n",
      " [0.28833497]\n",
      " [0.34249043]\n",
      " [0.51971227]\n",
      " [0.94640636]\n",
      " [0.9585656 ]\n",
      " [0.9523942 ]\n",
      " [0.9569088 ]\n",
      " [0.83737195]\n",
      " [0.15237328]\n",
      " [0.13261986]\n",
      " [0.18008447]\n",
      " [0.2799357 ]\n",
      " [0.5042585 ]\n",
      " [0.8667922 ]\n",
      " [0.92409444]\n",
      " [0.9224115 ]\n",
      " [0.95321536]\n",
      " [0.9488803 ]\n",
      " [0.9617771 ]\n",
      " [0.9464719 ]\n",
      " [0.95739603]\n",
      " [0.95651436]\n",
      " [0.96252215]\n",
      " [0.9575863 ]\n",
      " [0.95961463]\n",
      " [0.8502973 ]\n",
      " [0.504628  ]\n",
      " [0.12380376]\n",
      " [0.12224722]\n",
      " [0.1451008 ]\n",
      " [0.3207963 ]\n",
      " [0.39917544]\n",
      " [0.4733596 ]\n",
      " [0.30615008]\n",
      " [0.7865068 ]\n",
      " [0.51346034]\n",
      " [0.15359959]\n",
      " [0.23925948]\n",
      " [0.19015369]\n",
      " [0.10739842]\n",
      " [0.14127845]\n",
      " [0.09347785]\n",
      " [0.0989866 ]\n",
      " [0.09506258]\n",
      " [0.12587401]\n",
      " [0.16678077]\n",
      " [0.10895735]\n",
      " [0.52970064]\n",
      " [0.36072248]\n",
      " [0.30995756]\n",
      " [0.28401405]\n",
      " [0.5701895 ]\n",
      " [0.6527225 ]\n",
      " [0.6815237 ]\n",
      " [0.5335706 ]\n",
      " [0.86076486]\n",
      " [0.9074969 ]\n",
      " [0.7821743 ]\n",
      " [0.82480246]\n",
      " [0.8603821 ]\n",
      " [0.8672062 ]\n",
      " [0.8413613 ]\n",
      " [0.9031502 ]\n",
      " [0.34707952]\n",
      " [0.13874474]\n",
      " [0.9188622 ]\n",
      " [0.9447074 ]\n",
      " [0.96140385]\n",
      " [0.96117175]\n",
      " [0.96327055]\n",
      " [0.96516323]\n",
      " [0.96445715]\n",
      " [0.9646672 ]\n",
      " [0.9657664 ]\n",
      " [0.965154  ]\n",
      " [0.9655231 ]\n",
      " [0.9639361 ]\n",
      " [0.96301687]\n",
      " [0.9624884 ]\n",
      " [0.9615673 ]\n",
      " [0.96208155]\n",
      " [0.89435816]\n",
      " [0.67528397]\n",
      " [0.45318022]\n",
      " [0.9301628 ]\n",
      " [0.94471633]\n",
      " [0.93576694]\n",
      " [0.9578593 ]\n",
      " [0.96004343]\n",
      " [0.9572237 ]\n",
      " [0.9635297 ]\n",
      " [0.96504974]\n",
      " [0.9630324 ]\n",
      " [0.95581365]\n",
      " [0.9596703 ]\n",
      " [0.9585732 ]\n",
      " [0.9582219 ]\n",
      " [0.9514328 ]\n",
      " [0.940554  ]\n",
      " [0.91194713]\n",
      " [0.9008974 ]\n",
      " [0.9560551 ]\n",
      " [0.9136498 ]\n",
      " [0.9524311 ]\n",
      " [0.8787958 ]\n",
      " [0.81006634]\n",
      " [0.8874257 ]\n",
      " [0.82445496]\n",
      " [0.4531542 ]\n",
      " [0.39069396]\n",
      " [0.76509726]\n",
      " [0.88381314]\n",
      " [0.8317535 ]\n",
      " [0.9417621 ]\n",
      " [0.9425918 ]\n",
      " [0.94334096]\n",
      " [0.95435417]\n",
      " [0.96116227]\n",
      " [0.9636718 ]\n",
      " [0.96473384]\n",
      " [0.9595976 ]\n",
      " [0.9483552 ]\n",
      " [0.9527899 ]\n",
      " [0.95815134]\n",
      " [0.61348456]\n",
      " [0.5002744 ]\n",
      " [0.8668891 ]\n",
      " [0.8842225 ]\n",
      " [0.810797  ]\n",
      " [0.9064657 ]\n",
      " [0.95624727]\n",
      " [0.9622587 ]\n",
      " [0.9636049 ]\n",
      " [0.9641256 ]\n",
      " [0.96582913]\n",
      " [0.9651494 ]\n",
      " [0.96607715]\n",
      " [0.9647175 ]\n",
      " [0.9652948 ]\n",
      " [0.9647004 ]\n",
      " [0.9609436 ]\n",
      " [0.96212804]\n",
      " [0.96214294]\n",
      " [0.9612676 ]\n",
      " [0.95798534]\n",
      " [0.9578756 ]\n",
      " [0.9443175 ]\n",
      " [0.87495255]\n",
      " [0.3915005 ]\n",
      " [0.23692793]\n",
      " [0.11359683]\n",
      " [0.09996223]\n",
      " [0.10310447]\n",
      " [0.25229868]\n",
      " [0.14392146]\n",
      " [0.35240227]\n",
      " [0.53830934]\n",
      " [0.27127337]\n",
      " [0.720257  ]\n",
      " [0.9450885 ]\n",
      " [0.95713043]\n",
      " [0.96332026]\n",
      " [0.9641664 ]\n",
      " [0.9651202 ]\n",
      " [0.9642956 ]\n",
      " [0.96497166]\n",
      " [0.966351  ]\n",
      " [0.9668094 ]\n",
      " [0.96153754]\n",
      " [0.9640216 ]\n",
      " [0.96235067]\n",
      " [0.96283305]\n",
      " [0.9630091 ]\n",
      " [0.9619379 ]\n",
      " [0.9598388 ]\n",
      " [0.9590901 ]\n",
      " [0.961887  ]\n",
      " [0.9630517 ]\n",
      " [0.9642038 ]\n",
      " [0.96587276]\n",
      " [0.9654684 ]\n",
      " [0.9641731 ]\n",
      " [0.9600253 ]\n",
      " [0.9596474 ]\n",
      " [0.95817196]\n",
      " [0.9650113 ]\n",
      " [0.9644896 ]\n",
      " [0.9630704 ]\n",
      " [0.9637074 ]\n",
      " [0.9653369 ]\n",
      " [0.95872134]\n",
      " [0.9633782 ]\n",
      " [0.96114314]\n",
      " [0.9483515 ]\n",
      " [0.92582023]\n",
      " [0.9467686 ]\n",
      " [0.9401438 ]\n",
      " [0.7783985 ]\n",
      " [0.9258121 ]\n",
      " [0.9488045 ]\n",
      " [0.96110433]\n",
      " [0.9613819 ]\n",
      " [0.9537128 ]\n",
      " [0.9611757 ]\n",
      " [0.95949745]\n",
      " [0.9615166 ]\n",
      " [0.94342875]\n",
      " [0.9541669 ]\n",
      " [0.95290995]\n",
      " [0.93123055]\n",
      " [0.932775  ]\n",
      " [0.9584056 ]\n",
      " [0.954504  ]\n",
      " [0.95472515]\n",
      " [0.9595319 ]\n",
      " [0.9625796 ]\n",
      " [0.9636623 ]\n",
      " [0.9654325 ]\n",
      " [0.9657657 ]\n",
      " [0.9661262 ]\n",
      " [0.96652365]\n",
      " [0.9641487 ]\n",
      " [0.96163505]\n",
      " [0.9635055 ]\n",
      " [0.80110157]\n",
      " [0.5154483 ]\n",
      " [0.8049495 ]\n",
      " [0.8563325 ]\n",
      " [0.15073869]\n",
      " [0.1637632 ]\n",
      " [0.1596854 ]\n",
      " [0.12688494]\n",
      " [0.08753359]\n",
      " [0.09326884]\n",
      " [0.08396801]\n",
      " [0.08884668]\n",
      " [0.09731534]\n",
      " [0.11844549]\n",
      " [0.1372169 ]\n",
      " [0.14064541]\n",
      " [0.20118698]\n",
      " [0.2445974 ]\n",
      " [0.520869  ]\n",
      " [0.7948446 ]\n",
      " [0.77794534]\n",
      " [0.7479085 ]\n",
      " [0.9364351 ]\n",
      " [0.9304685 ]\n",
      " [0.916512  ]\n",
      " [0.23309839]\n",
      " [0.13246688]\n",
      " [0.09971946]\n",
      " [0.21656412]\n",
      " [0.21020582]\n",
      " [0.6485242 ]\n",
      " [0.86608016]\n",
      " [0.8631339 ]\n",
      " [0.95282054]\n",
      " [0.962005  ]\n",
      " [0.96444285]\n",
      " [0.96436375]\n",
      " [0.9629104 ]\n",
      " [0.9613012 ]\n",
      " [0.9514233 ]\n",
      " [0.93446827]\n",
      " [0.89780056]\n",
      " [0.77474594]\n",
      " [0.506702  ]\n",
      " [0.755796  ]\n",
      " [0.9503932 ]\n",
      " [0.96157575]\n",
      " [0.96389645]\n",
      " [0.96413374]\n",
      " [0.9647604 ]\n",
      " [0.965689  ]\n",
      " [0.96546197]\n",
      " [0.96411496]\n",
      " [0.96610814]\n",
      " [0.9654292 ]\n",
      " [0.9655137 ]\n",
      " [0.96528065]\n",
      " [0.9633808 ]\n",
      " [0.96565855]\n",
      " [0.96439314]\n",
      " [0.9655726 ]\n",
      " [0.9664396 ]\n",
      " [0.96344423]\n",
      " [0.9658067 ]\n",
      " [0.96436936]\n",
      " [0.9630527 ]\n",
      " [0.96431005]\n",
      " [0.96356535]\n",
      " [0.960315  ]\n",
      " [0.9474689 ]\n",
      " [0.9287367 ]\n",
      " [0.82137835]\n",
      " [0.9239323 ]\n",
      " [0.8623999 ]\n",
      " [0.6616973 ]\n",
      " [0.3532345 ]\n",
      " [0.68904865]\n",
      " [0.61536455]\n",
      " [0.86857337]\n",
      " [0.10326225]\n",
      " [0.11760968]\n",
      " [0.10352463]\n",
      " [0.08336353]\n",
      " [0.08121982]\n",
      " [0.09879461]\n",
      " [0.12175575]\n",
      " [0.08070785]\n",
      " [0.08195445]\n",
      " [0.08190984]\n",
      " [0.08591413]\n",
      " [0.08113411]\n",
      " [0.09320459]\n",
      " [0.08597636]\n",
      " [0.09759474]\n",
      " [0.1209161 ]\n",
      " [0.12149405]\n",
      " [0.11938328]\n",
      " [0.08299026]\n",
      " [0.08817905]\n",
      " [0.08008707]\n",
      " [0.09001938]\n",
      " [0.16783959]\n",
      " [0.43850484]\n",
      " [0.7757162 ]\n",
      " [0.5408194 ]\n",
      " [0.9341004 ]\n",
      " [0.95862186]\n",
      " [0.9574237 ]\n",
      " [0.9536701 ]\n",
      " [0.94287074]\n",
      " [0.95051455]\n",
      " [0.95598805]\n",
      " [0.96340925]\n",
      " [0.96306753]\n",
      " [0.9623997 ]\n",
      " [0.96282053]\n",
      " [0.9354838 ]\n",
      " [0.96429706]\n",
      " [0.96245897]\n",
      " [0.9647547 ]\n",
      " [0.96576667]\n",
      " [0.9651452 ]\n",
      " [0.9565687 ]\n",
      " [0.9522445 ]\n",
      " [0.9471752 ]\n",
      " [0.5326683 ]\n",
      " [0.13810608]\n",
      " [0.12277681]\n",
      " [0.0853962 ]\n",
      " [0.08499759]\n",
      " [0.08134645]\n",
      " [0.08432388]\n",
      " [0.0850898 ]\n",
      " [0.09460488]\n",
      " [0.1096358 ]\n",
      " [0.09676078]\n",
      " [0.1087659 ]\n",
      " [0.10308355]\n",
      " [0.16152236]\n",
      " [0.23986888]\n",
      " [0.72399133]\n",
      " [0.6269239 ]\n",
      " [0.3172479 ]\n",
      " [0.13376811]\n",
      " [0.31935585]\n",
      " [0.14784113]\n",
      " [0.42391247]\n",
      " [0.8949628 ]\n",
      " [0.9536277 ]\n",
      " [0.9615185 ]\n",
      " [0.96189845]\n",
      " [0.96423155]\n",
      " [0.9649839 ]\n",
      " [0.9615731 ]\n",
      " [0.96409285]\n",
      " [0.9638627 ]\n",
      " [0.96408236]\n",
      " [0.77560663]\n",
      " [0.73675597]\n",
      " [0.77663314]\n",
      " [0.14890277]\n",
      " [0.20704669]\n",
      " [0.24819762]\n",
      " [0.22271287]\n",
      " [0.19292808]\n",
      " [0.09147194]\n",
      " [0.12422752]\n",
      " [0.1099849 ]\n",
      " [0.15665361]\n",
      " [0.21469465]\n",
      " [0.18940377]\n",
      " [0.5839616 ]\n",
      " [0.91438204]\n",
      " [0.94294477]\n",
      " [0.9439074 ]\n",
      " [0.9583436 ]\n",
      " [0.9615088 ]\n",
      " [0.9595317 ]\n",
      " [0.9580344 ]\n",
      " [0.950284  ]\n",
      " [0.8379805 ]\n",
      " [0.95059097]\n",
      " [0.9549125 ]\n",
      " [0.9628844 ]\n",
      " [0.9597494 ]\n",
      " [0.9430203 ]\n",
      " [0.56690305]\n",
      " [0.1573888 ]\n",
      " [0.11975962]\n",
      " [0.19957352]\n",
      " [0.38841718]\n",
      " [0.40415603]\n",
      " [0.164051  ]\n",
      " [0.15973184]\n",
      " [0.11069316]\n",
      " [0.1483984 ]\n",
      " [0.16594973]\n",
      " [0.21899608]\n",
      " [0.19385251]\n",
      " [0.18251675]\n",
      " [0.89500797]\n",
      " [0.5059443 ]\n",
      " [0.10798946]\n",
      " [0.11781195]\n",
      " [0.20529082]\n",
      " [0.41469717]\n",
      " [0.714025  ]\n",
      " [0.93514156]\n",
      " [0.86421084]\n",
      " [0.9504782 ]\n",
      " [0.95232445]\n",
      " [0.4265843 ]\n",
      " [0.11572209]\n",
      " [0.09751996]\n",
      " [0.08434102]\n",
      " [0.09205183]\n",
      " [0.08058396]\n",
      " [0.08831802]\n",
      " [0.09056818]\n",
      " [0.0877496 ]\n",
      " [0.08414194]\n",
      " [0.07994339]\n",
      " [0.08434573]\n",
      " [0.07864919]\n",
      " [0.08072135]\n",
      " [0.08011886]\n",
      " [0.08000332]\n",
      " [0.0840722 ]\n",
      " [0.09474006]\n",
      " [0.11385453]\n",
      " [0.10417208]\n",
      " [0.12361836]\n",
      " [0.34626454]\n",
      " [0.34462112]\n",
      " [0.33899486]\n",
      " [0.44172695]\n",
      " [0.35567868]\n",
      " [0.6073121 ]\n",
      " [0.24358875]\n",
      " [0.42671964]\n",
      " [0.28706187]\n",
      " [0.67769784]\n",
      " [0.730934  ]\n",
      " [0.73642486]\n",
      " [0.80288655]\n",
      " [0.9368707 ]\n",
      " [0.15944538]\n",
      " [0.4528641 ]\n",
      " [0.3761291 ]\n",
      " [0.8374113 ]\n",
      " [0.9270114 ]\n",
      " [0.94823754]\n",
      " [0.6887063 ]\n",
      " [0.15986139]\n",
      " [0.19539168]\n",
      " [0.13945875]\n",
      " [0.15681475]\n",
      " [0.15109313]\n",
      " [0.42909586]\n",
      " [0.626649  ]\n",
      " [0.8785624 ]\n",
      " [0.942829  ]\n",
      " [0.9568872 ]\n",
      " [0.9598243 ]\n",
      " [0.96332383]\n",
      " [0.96262157]\n",
      " [0.96569085]\n",
      " [0.963567  ]\n",
      " [0.9651866 ]\n",
      " [0.9586486 ]\n",
      " [0.9450751 ]\n",
      " [0.8998991 ]\n",
      " [0.91153836]\n",
      " [0.49427187]\n",
      " [0.32500917]\n",
      " [0.32447904]\n",
      " [0.94738394]\n",
      " [0.90595526]\n",
      " [0.94309676]\n",
      " [0.946746  ]\n",
      " [0.9577223 ]\n",
      " [0.96412873]\n",
      " [0.96539927]\n",
      " [0.9632541 ]\n",
      " [0.9622471 ]\n",
      " [0.93066514]\n",
      " [0.20578414]\n",
      " [0.16638291]\n",
      " [0.099951  ]\n",
      " [0.08908036]\n",
      " [0.08260885]\n",
      " [0.08914015]\n",
      " [0.08428457]\n",
      " [0.08376098]\n",
      " [0.08798778]\n",
      " [0.08360508]\n",
      " [0.08727658]\n",
      " [0.08999687]\n",
      " [0.08244187]\n",
      " [0.08112344]\n",
      " [0.0837481 ]\n",
      " [0.0820379 ]\n",
      " [0.08028966]\n",
      " [0.08333081]\n",
      " [0.09072831]\n",
      " [0.09173629]\n",
      " [0.23570374]\n",
      " [0.21831188]\n",
      " [0.42590496]\n",
      " [0.4502944 ]\n",
      " [0.7733563 ]\n",
      " [0.7837039 ]\n",
      " [0.8348152 ]\n",
      " [0.8837924 ]\n",
      " [0.89254546]\n",
      " [0.94308496]\n",
      " [0.95166105]\n",
      " [0.95840955]\n",
      " [0.9472694 ]\n",
      " [0.92481554]\n",
      " [0.8374727 ]\n",
      " [0.4721685 ]\n",
      " [0.85814923]\n",
      " [0.9385051 ]\n",
      " [0.9546858 ]\n",
      " [0.9543284 ]\n",
      " [0.93624777]\n",
      " [0.9625315 ]\n",
      " [0.9554919 ]\n",
      " [0.94103277]\n",
      " [0.49705234]\n",
      " [0.4856533 ]\n",
      " [0.14684299]\n",
      " [0.11762667]\n",
      " [0.24423325]\n",
      " [0.54724663]\n",
      " [0.17703515]\n",
      " [0.17955917]\n",
      " [0.12834498]\n",
      " [0.21076691]\n",
      " [0.11784475]\n",
      " [0.1180727 ]\n",
      " [0.10358254]\n",
      " [0.0998329 ]\n",
      " [0.09821622]\n",
      " [0.12203316]]\n",
      "실제 레이어 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "실제 값 : 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[216  81]\n",
      " [ 31 374]]\n",
      "■■■예측 성공■■■\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------ 실제\n",
    "\n",
    "\n",
    "TF = 25 # 고정값\n",
    "\n",
    "cycle = 20 #고정값\n",
    "\n",
    "VA = 0 #초기값 0\n",
    "DE = 25 #초기값 25\n",
    "NUM = 1 # 초기값 1, 매 차례마다 +1\n",
    "for x in range(10000):\n",
    "    df=index_dic[\"KS11\"]\n",
    "    MA_26=df[\"Close\"].rolling(26).mean().dropna()\n",
    "    y=np.where(df[\"Close\"][TF:].shift(-1)>MA_26.shift(-1),1,0)\n",
    "\n",
    "    df = df.values\n",
    "    df.astype('float32')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df = scaler.fit_transform(df)\n",
    "    X=df[TF:]\n",
    "\n",
    "\n",
    "    train_size = int(len(df)*0.7)\n",
    "    X_train2 = X[:train_size]\n",
    "    X_test2 = X[train_size:] \n",
    "    y_train2 = y[:train_size]\n",
    "    y_test2 = y[train_size:]\n",
    "\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    X_train = np.reshape(X_train2, (X_train2.shape[0], 1, X_train2.shape[1]))\n",
    "    X_test = np.reshape(X_test2, (X_test2.shape[0], 1, X_test2.shape[1]))\n",
    "    y_train=y_train2\n",
    "    y_test=y_test2\n",
    "\n",
    "    # simple lstm network learning\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(36, input_shape=(1, 12)))\n",
    "    for i in range(5):\n",
    "        model.add(Dense(36,activation='sigmoid'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=16,validation_split=0.1)\n",
    "\n",
    "\n",
    "    print(\"{}번째 리밸런싱 성공\".format(NUM))\n",
    "    print(\"Train,Test의 loss, score :\", model.evaluate(X_test,y_test))\n",
    "    \n",
    "    if(model.predict(X_test)[-1]>0.5):\n",
    "        answer=1\n",
    "        print(\"1~{}영업일까지를 예측 데이터로 {}영업일은 상승 예측\".format(NUM*cycle,NUM*cycle+1))\n",
    "    else:\n",
    "        answer=0\n",
    "        print(\"1~{}영업일까지를 예측 데이터로 {}영업일은 하락 예측\".format(NUM*cycle,NUM*cycle+1))\n",
    "    print(\"딥러닝이 예측한 값들 :\",model.predict(X_test))\n",
    "    print(\"실제 레이어 :\",y_test)\n",
    "    print(\"실제 값 :\", y_test[-1] )\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test,np.where(model.predict(X_test)>0.5,1,0)))\n",
    "\n",
    "    if (answer==y_test[-1]):\n",
    "          print(\"■■■예측 성공■■■\")\n",
    "    else:\n",
    "          print(\"□□□예측 실패□□□\")\n",
    "    DE=DE+cycle\n",
    "    VA=VA+cycle\n",
    "    NUM=NUM+1\n",
    "\n",
    "\n",
    "    if (train_size>=int(len(df)*0.75)):\n",
    "        print(\"끝까지 도달했습니다\")\n",
    "        break\n",
    "        \n",
    "    print(\"------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(702,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2423, 12)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
