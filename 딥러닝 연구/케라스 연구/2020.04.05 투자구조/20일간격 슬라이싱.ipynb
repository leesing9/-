{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import FinanceDataReader as fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특성 추가 ------------------------------------------\n",
    "    #이동평균선\n",
    "def get_MA(df):\n",
    "    MA_26=df[\"Close\"].rolling(26).mean()\n",
    "    MA_52=df[\"Close\"].rolling(52).mean()\n",
    "    df=df.assign(MA_26=MA_26,MA_52=MA_52).dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "    #스토캐스틱\n",
    "def get_stochastic(df, n=15, m=5, t=3):\n",
    "    # n일중 최고가\n",
    "    ndays_high = df.High.rolling(window=n, min_periods=1).max()\n",
    "    # n일중 최저가\n",
    "    ndays_low = df.Low.rolling(window=n, min_periods=1).min()\n",
    " \n",
    "    # Fast%K 계산\n",
    "    kdj_k = ((df.Close - ndays_low) / (ndays_high - ndays_low))*100\n",
    "    # Fast%D (=Slow%K) 계산\n",
    "    kdj_d = kdj_k.ewm(span=m).mean()\n",
    "    # Slow%D 계산\n",
    "    kdj_j = kdj_d.ewm(span=t).mean()\n",
    " \n",
    "    # dataframe에 컬럼 추가\n",
    "    df = df.assign(kdj_k=kdj_k, kdj_d=kdj_d, kdj_j=kdj_j).dropna()\n",
    "    \n",
    "    return df\n",
    "   \n",
    "    #시간\n",
    "def get_time(df):\n",
    "    time=np.linspace(0,10,len(df),endpoint=False).reshape(-1,1)\n",
    "    df=df.assign(time=time)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Program Files\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1696.14"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1=KS11.ix[::19,:][\"Close\"][:-1] # 1일차,20,40,\n",
    "y_2=KS11.ix[::19,:][\"Close\"][1:] # 20일차,40,60..\n",
    "\n",
    "\n",
    "#문제점 : 1~20일차로 21일차를 예측하는데 트레이닝 시킬 데이터가없다\n",
    "y_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS11 = fdr.DataReader(\"KS11\",\"2018-01-01\",\"2019-01-01\")\n",
    "KQ11= fdr.DataReader(\"KQ11\",\"2018-01-01\",\"2019-01-01\")\n",
    "US500 = fdr.DataReader(\"US500\",\"2018-01-01\",\"2019-01-01\")\n",
    "HSI = fdr.DataReader(\"HSI\",\"2018-01-01\",\"2019-01-01\")\n",
    "IXIC = fdr.DataReader(\"IXIC\",\"2018-01-01\",\"2019-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016490331995622047"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y_1[x+1]-y_1[x])/y_1[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1~19일 차 ---------------------------------\n",
      "상승 예측된 인덱스 :  KS11\n",
      "상승 예측된 인덱스 :  KQ11\n",
      "상승 예측된 인덱스 :  IXIC\n",
      "상승 예측된 인덱스 :  HSI\n",
      "상승 예측된 인덱스 :  US500\n",
      "투자 결과 :  10469.691855138159\n",
      "21~39일 차 ---------------------------------\n",
      "상승 예측된 인덱스 :  KS11\n",
      "상승 예측된 인덱스 :  KQ11\n",
      "상승 예측된 인덱스 :  IXIC\n",
      "상승 예측된 인덱스 :  HSI\n",
      "상승 예측된 인덱스 :  US500\n",
      "투자 결과 :  9723.11093632083\n",
      "41~59일 차 ---------------------------------\n",
      "상승 예측된 인덱스 :  KS11\n",
      "상승 예측된 인덱스 :  KQ11\n",
      "상승 예측된 인덱스 :  IXIC\n",
      "상승 예측된 인덱스 :  HSI\n",
      "상승 예측된 인덱스 :  US500\n",
      "투자 결과 :  9687.604763362338\n",
      "61~79일 차 ---------------------------------\n",
      "상승 예측된 인덱스 :  KS11\n",
      "상승 예측된 인덱스 :  KQ11\n",
      "상승 예측된 인덱스 :  IXIC\n",
      "상승 예측된 인덱스 :  HSI\n",
      "상승 예측된 인덱스 :  US500\n",
      "투자 결과 :  10044.15941020481\n",
      "81~99일 차 ---------------------------------\n",
      "상승 예측된 인덱스 :  KS11\n",
      "상승 예측된 인덱스 :  KQ11\n",
      "상승 예측된 인덱스 :  IXIC\n",
      "상승 예측된 인덱스 :  HSI\n",
      "상승 예측된 인덱스 :  US500\n",
      "투자 결과 :  10159.832827146114\n",
      "101~119일 차 ---------------------------------\n",
      "상승 예측된 인덱스 :  KS11\n",
      "상승 예측된 인덱스 :  KQ11\n",
      "상승 예측된 인덱스 :  IXIC\n",
      "상승 예측된 인덱스 :  HSI\n",
      "상승 예측된 인덱스 :  US500\n",
      "투자 결과 :  10245.819157602185\n",
      "121~139일 차 ---------------------------------\n",
      "상승 예측된 인덱스 :  KS11\n",
      "상승 예측된 인덱스 :  KQ11\n",
      "상승 예측된 인덱스 :  IXIC\n",
      "상승 예측된 인덱스 :  HSI\n",
      "상승 예측된 인덱스 :  US500\n",
      "투자 결과 :  10077.887223617277\n",
      "141~159일 차 ---------------------------------\n",
      "상승 예측된 인덱스 :  KS11\n",
      "상승 예측된 인덱스 :  KQ11\n",
      "상승 예측된 인덱스 :  IXIC\n",
      "상승 예측된 인덱스 :  HSI\n",
      "상승 예측된 인덱스 :  US500\n",
      "투자 결과 :  10186.59127336853\n",
      "161~179일 차 ---------------------------------\n",
      "상승 예측된 인덱스 :  KS11\n",
      "상승 예측된 인덱스 :  KQ11\n",
      "상승 예측된 인덱스 :  IXIC\n",
      "상승 예측된 인덱스 :  HSI\n",
      "상승 예측된 인덱스 :  US500\n",
      "투자 결과 :  10085.751932660029\n",
      "181~199일 차 ---------------------------------\n",
      "상승 예측된 인덱스 :  KS11\n",
      "상승 예측된 인덱스 :  KQ11\n",
      "상승 예측된 인덱스 :  IXIC\n",
      "상승 예측된 인덱스 :  HSI\n",
      "상승 예측된 인덱스 :  US500\n",
      "투자 결과 :  10164.90331995622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>인덱스</th>\n",
       "      <th>예측값</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>영업일</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1~19일 차</td>\n",
       "      <td>KS11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1~19일 차</td>\n",
       "      <td>KQ11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1~19일 차</td>\n",
       "      <td>IXIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1~19일 차</td>\n",
       "      <td>HSI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1~19일 차</td>\n",
       "      <td>US500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21~39일 차</td>\n",
       "      <td>KS11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21~39일 차</td>\n",
       "      <td>KQ11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21~39일 차</td>\n",
       "      <td>IXIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21~39일 차</td>\n",
       "      <td>HSI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21~39일 차</td>\n",
       "      <td>US500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41~59일 차</td>\n",
       "      <td>KS11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41~59일 차</td>\n",
       "      <td>KQ11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41~59일 차</td>\n",
       "      <td>IXIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41~59일 차</td>\n",
       "      <td>HSI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41~59일 차</td>\n",
       "      <td>US500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61~79일 차</td>\n",
       "      <td>KS11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61~79일 차</td>\n",
       "      <td>KQ11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61~79일 차</td>\n",
       "      <td>IXIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61~79일 차</td>\n",
       "      <td>HSI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61~79일 차</td>\n",
       "      <td>US500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81~99일 차</td>\n",
       "      <td>KS11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81~99일 차</td>\n",
       "      <td>KQ11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81~99일 차</td>\n",
       "      <td>IXIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81~99일 차</td>\n",
       "      <td>HSI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81~99일 차</td>\n",
       "      <td>US500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101~119일 차</td>\n",
       "      <td>KS11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101~119일 차</td>\n",
       "      <td>KQ11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101~119일 차</td>\n",
       "      <td>IXIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101~119일 차</td>\n",
       "      <td>HSI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101~119일 차</td>\n",
       "      <td>US500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121~139일 차</td>\n",
       "      <td>KS11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121~139일 차</td>\n",
       "      <td>KQ11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121~139일 차</td>\n",
       "      <td>IXIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121~139일 차</td>\n",
       "      <td>HSI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121~139일 차</td>\n",
       "      <td>US500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141~159일 차</td>\n",
       "      <td>KS11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141~159일 차</td>\n",
       "      <td>KQ11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141~159일 차</td>\n",
       "      <td>IXIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141~159일 차</td>\n",
       "      <td>HSI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141~159일 차</td>\n",
       "      <td>US500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161~179일 차</td>\n",
       "      <td>KS11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161~179일 차</td>\n",
       "      <td>KQ11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161~179일 차</td>\n",
       "      <td>IXIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161~179일 차</td>\n",
       "      <td>HSI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161~179일 차</td>\n",
       "      <td>US500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181~199일 차</td>\n",
       "      <td>KS11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181~199일 차</td>\n",
       "      <td>KQ11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181~199일 차</td>\n",
       "      <td>IXIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181~199일 차</td>\n",
       "      <td>HSI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181~199일 차</td>\n",
       "      <td>US500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              인덱스 예측값\n",
       "영업일                  \n",
       "1~19일 차      KS11   1\n",
       "1~19일 차      KQ11   1\n",
       "1~19일 차      IXIC   1\n",
       "1~19일 차       HSI   1\n",
       "1~19일 차     US500   1\n",
       "21~39일 차     KS11   1\n",
       "21~39일 차     KQ11   1\n",
       "21~39일 차     IXIC   1\n",
       "21~39일 차      HSI   1\n",
       "21~39일 차    US500   1\n",
       "41~59일 차     KS11   1\n",
       "41~59일 차     KQ11   1\n",
       "41~59일 차     IXIC   1\n",
       "41~59일 차      HSI   1\n",
       "41~59일 차    US500   1\n",
       "61~79일 차     KS11   1\n",
       "61~79일 차     KQ11   1\n",
       "61~79일 차     IXIC   1\n",
       "61~79일 차      HSI   1\n",
       "61~79일 차    US500   1\n",
       "81~99일 차     KS11   1\n",
       "81~99일 차     KQ11   1\n",
       "81~99일 차     IXIC   1\n",
       "81~99일 차      HSI   1\n",
       "81~99일 차    US500   1\n",
       "101~119일 차   KS11   1\n",
       "101~119일 차   KQ11   1\n",
       "101~119일 차   IXIC   1\n",
       "101~119일 차    HSI   1\n",
       "101~119일 차  US500   1\n",
       "121~139일 차   KS11   1\n",
       "121~139일 차   KQ11   1\n",
       "121~139일 차   IXIC   1\n",
       "121~139일 차    HSI   1\n",
       "121~139일 차  US500   1\n",
       "141~159일 차   KS11   1\n",
       "141~159일 차   KQ11   1\n",
       "141~159일 차   IXIC   1\n",
       "141~159일 차    HSI   1\n",
       "141~159일 차  US500   1\n",
       "161~179일 차   KS11   1\n",
       "161~179일 차   KQ11   1\n",
       "161~179일 차   IXIC   1\n",
       "161~179일 차    HSI   1\n",
       "161~179일 차  US500   1\n",
       "181~199일 차   KS11   1\n",
       "181~199일 차   KQ11   1\n",
       "181~199일 차   IXIC   1\n",
       "181~199일 차    HSI   1\n",
       "181~199일 차  US500   1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "초기돈=10000\n",
    "d=1\n",
    "dd=19\n",
    "상승예측리스트=[]\n",
    "총df=pd.DataFrame(columns=[\"영업일\",\"인덱스\",\"예측값\"])\n",
    "for x in range(10): #예측머신돌리기\n",
    "    if (x==0): #day만들기\n",
    "        day= str(d) + \"~\" + str(dd) + \"일 차\" \n",
    "    else:\n",
    "        day= str(d+(20*x)) +\"~\" + str(dd+(20*x)) + \"일 차\"\n",
    "    print(day,\"---------------------------------\")\n",
    "    for 인덱스,인덱스명 in zip([KS11,KQ11,IXIC,HSI,US500],[\"KS11\",\"KQ11\",\"IXIC\",\"HSI\",\"US500\"]):\n",
    "        \n",
    "        \n",
    "        #예측머신\n",
    "        \n",
    "        \n",
    "        ### 해야할것 : many to one 적용해서 for문반복시키기 \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #예측머신\n",
    "        # ---------predict -> 0 or 1 나옴\n",
    "        \n",
    "    \n",
    "        예측=1\n",
    "        턴df=pd.DataFrame(data={\"영업일\":[day],\"인덱스\":[인덱스명],\"예측값\":[예측] }\n",
    "                         , columns=[\"영업일\",\"인덱스\",\"예측값\"])\n",
    "        총df=pd.concat([총df,턴df])\n",
    "        \n",
    "        \n",
    "        투잣돈=초기돈/턴df[\"예측값\"].sum()\n",
    "        if int(턴df[\"예측값\"])==1:\n",
    "            print(\"상승 예측된 인덱스 : \",인덱스명)\n",
    "            y_1=인덱스.ix[::19,:][\"Close\"][:-1] # 1일차,20,40,\n",
    "            투자결과 = 투잣돈 + 투잣돈 * ((y_1[x+1]-y_1[x])/y_1[x])\n",
    "    print(\"투자 결과 : \",투자결과)\n",
    "    #MONEY = 투잣돈 * A의 20일후 change + 투잣돈 * B의 20일후 change #\"20일차MONEY\"출력\n",
    "    \n",
    "총df = 총df.set_index(\"영업일\")\n",
    "총df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6931 - acc: 1.0000\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6926 - acc: 1.0000\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6921 - acc: 1.0000\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6916 - acc: 1.0000\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6911 - acc: 1.0000\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6907 - acc: 1.0000\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6902 - acc: 1.0000\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6897 - acc: 1.0000\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6892 - acc: 1.0000\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6887 - acc: 1.0000\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6882 - acc: 1.0000\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6877 - acc: 1.0000\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6872 - acc: 1.0000\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6867 - acc: 1.0000\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6862 - acc: 1.0000\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6857 - acc: 1.0000\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6852 - acc: 1.0000\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6847 - acc: 1.0000\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6842 - acc: 1.0000\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6837 - acc: 1.0000\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6832 - acc: 1.0000\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6827 - acc: 1.0000\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6822 - acc: 1.0000\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6817 - acc: 1.0000\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6812 - acc: 1.0000\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6807 - acc: 1.0000\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6802 - acc: 1.0000\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6798 - acc: 1.0000\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6793 - acc: 1.0000\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6788 - acc: 1.0000\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6783 - acc: 1.0000\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6778 - acc: 1.0000\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6773 - acc: 1.0000\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6768 - acc: 1.0000\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6763 - acc: 1.0000\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6758 - acc: 1.0000\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6753 - acc: 1.0000\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6749 - acc: 1.0000\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6744 - acc: 1.0000\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6739 - acc: 1.0000\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6734 - acc: 1.0000\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6729 - acc: 1.0000\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6724 - acc: 1.0000\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6719 - acc: 1.0000\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6714 - acc: 1.0000\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 1.0000\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6705 - acc: 1.0000\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6700 - acc: 1.0000\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6695 - acc: 1.0000\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6690 - acc: 1.0000\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6685 - acc: 1.0000\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6680 - acc: 1.0000\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6676 - acc: 1.0000\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6671 - acc: 1.0000\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6666 - acc: 1.0000\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6661 - acc: 1.0000\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6656 - acc: 1.0000\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6652 - acc: 1.0000\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6647 - acc: 1.0000\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6642 - acc: 1.0000\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6637 - acc: 1.0000\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6632 - acc: 1.0000\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6628 - acc: 1.0000\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6623 - acc: 1.0000\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6618 - acc: 1.0000\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6613 - acc: 1.0000\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6608 - acc: 1.0000\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6604 - acc: 1.0000\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6599 - acc: 1.0000\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6594 - acc: 1.0000\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6589 - acc: 1.0000\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6585 - acc: 1.0000\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6580 - acc: 1.0000\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6575 - acc: 1.0000\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6570 - acc: 1.0000\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6566 - acc: 1.0000\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6561 - acc: 1.0000\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6556 - acc: 1.0000\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6551 - acc: 1.0000\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6547 - acc: 1.0000\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6542 - acc: 1.0000\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6537 - acc: 1.0000\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6532 - acc: 1.0000\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6528 - acc: 1.0000\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6523 - acc: 1.0000\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6518 - acc: 1.0000\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6514 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6509 - acc: 1.0000\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6504 - acc: 1.0000\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6499 - acc: 1.0000\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6495 - acc: 1.0000\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6490 - acc: 1.0000\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6485 - acc: 1.0000\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6481 - acc: 1.0000\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6476 - acc: 1.0000\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6471 - acc: 1.0000\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6467 - acc: 1.0000\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6462 - acc: 1.0000\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6457 - acc: 1.0000\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6453 - acc: 1.0000\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6448 - acc: 1.0000\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6443 - acc: 1.0000\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6439 - acc: 1.0000\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6434 - acc: 1.0000\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6429 - acc: 1.0000\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6425 - acc: 1.0000\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6420 - acc: 1.0000\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6416 - acc: 1.0000\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6411 - acc: 1.0000\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6406 - acc: 1.0000\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6402 - acc: 1.0000\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6397 - acc: 1.0000\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6392 - acc: 1.0000\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6388 - acc: 1.0000\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6383 - acc: 1.0000\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6379 - acc: 1.0000\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6374 - acc: 1.0000\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6369 - acc: 1.0000\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6365 - acc: 1.0000\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6360 - acc: 1.0000\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6356 - acc: 1.0000\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6351 - acc: 1.0000\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6346 - acc: 1.0000\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6342 - acc: 1.0000\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6337 - acc: 1.0000\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6333 - acc: 1.0000\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6328 - acc: 1.0000\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6324 - acc: 1.0000\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6319 - acc: 1.0000\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6315 - acc: 1.0000\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6310 - acc: 1.0000\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6305 - acc: 1.0000\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6301 - acc: 1.0000\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6296 - acc: 1.0000\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6292 - acc: 1.0000\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6287 - acc: 1.0000\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6283 - acc: 1.0000\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6278 - acc: 1.0000\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6274 - acc: 1.0000\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6269 - acc: 1.0000\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6265 - acc: 1.0000\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6260 - acc: 1.0000\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6256 - acc: 1.0000\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6251 - acc: 1.0000\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6247 - acc: 1.0000\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6242 - acc: 1.0000\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6238 - acc: 1.0000\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6233 - acc: 1.0000\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6229 - acc: 1.0000\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6224 - acc: 1.0000\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6220 - acc: 1.0000\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6215 - acc: 1.0000\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6211 - acc: 1.0000\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6206 - acc: 1.0000\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6202 - acc: 1.0000\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6197 - acc: 1.0000\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6193 - acc: 1.0000\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6188 - acc: 1.0000\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6184 - acc: 1.0000\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6180 - acc: 1.0000\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6175 - acc: 1.0000\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6171 - acc: 1.0000\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6166 - acc: 1.0000\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6162 - acc: 1.0000\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6157 - acc: 1.0000\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6153 - acc: 1.0000\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6148 - acc: 1.0000\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6144 - acc: 1.0000\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6140 - acc: 1.0000\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6135 - acc: 1.0000\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6131 - acc: 1.0000\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6126 - acc: 1.0000\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6122 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6118 - acc: 1.0000\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6113 - acc: 1.0000\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6109 - acc: 1.0000\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6104 - acc: 1.0000\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6100 - acc: 1.0000\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6096 - acc: 1.0000\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6091 - acc: 1.0000\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6087 - acc: 1.0000\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6082 - acc: 1.0000\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6078 - acc: 1.0000\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6074 - acc: 1.0000\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6069 - acc: 1.0000\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6065 - acc: 1.0000\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6061 - acc: 1.0000\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6056 - acc: 1.0000\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6052 - acc: 1.0000\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6048 - acc: 1.0000\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6043 - acc: 1.0000\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6039 - acc: 1.0000\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6035 - acc: 1.0000\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6030 - acc: 1.0000\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6026 - acc: 1.0000\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6022 - acc: 1.0000\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6017 - acc: 1.0000\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6013 - acc: 1.0000\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6009 - acc: 1.0000\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6004 - acc: 1.0000\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6000 - acc: 1.0000\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5996 - acc: 1.0000\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5991 - acc: 1.0000\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5987 - acc: 1.0000\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5983 - acc: 1.0000\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5978 - acc: 1.0000\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5974 - acc: 1.0000\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5970 - acc: 1.0000\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5966 - acc: 1.0000\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5961 - acc: 1.0000\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5957 - acc: 1.0000\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5953 - acc: 1.0000\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5949 - acc: 1.0000\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5944 - acc: 1.0000\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5940 - acc: 1.0000\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5936 - acc: 1.0000\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5931 - acc: 1.0000\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5927 - acc: 1.0000\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5923 - acc: 1.0000\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5919 - acc: 1.0000\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5914 - acc: 1.0000\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5910 - acc: 1.0000\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5906 - acc: 1.0000\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5902 - acc: 1.0000\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5898 - acc: 1.0000\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5893 - acc: 1.0000\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5889 - acc: 1.0000\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5885 - acc: 1.0000\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5881 - acc: 1.0000\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5876 - acc: 1.0000\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5872 - acc: 1.0000\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5868 - acc: 1.0000\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5864 - acc: 1.0000\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5860 - acc: 1.0000\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5855 - acc: 1.0000\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5851 - acc: 1.0000\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5847 - acc: 1.0000\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5843 - acc: 1.0000\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5839 - acc: 1.0000\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5834 - acc: 1.0000\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5830 - acc: 1.0000\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5826 - acc: 1.0000\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5822 - acc: 1.0000\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5818 - acc: 1.0000\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5814 - acc: 1.0000\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5809 - acc: 1.0000\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5805 - acc: 1.0000\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5801 - acc: 1.0000\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5797 - acc: 1.0000\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5793 - acc: 1.0000\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5789 - acc: 1.0000\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5785 - acc: 1.0000\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5780 - acc: 1.0000\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5776 - acc: 1.0000\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5772 - acc: 1.0000\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5768 - acc: 1.0000\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5764 - acc: 1.0000\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5760 - acc: 1.0000\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5756 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5752 - acc: 1.0000\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5747 - acc: 1.0000\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5743 - acc: 1.0000\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5739 - acc: 1.0000\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5735 - acc: 1.0000\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5731 - acc: 1.0000\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5727 - acc: 1.0000\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5723 - acc: 1.0000\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5719 - acc: 1.0000\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5715 - acc: 1.0000\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5711 - acc: 1.0000\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5706 - acc: 1.0000\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5702 - acc: 1.0000\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5698 - acc: 1.0000\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5694 - acc: 1.0000\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5690 - acc: 1.0000\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5686 - acc: 1.0000\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5682 - acc: 1.0000\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5678 - acc: 1.0000\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5674 - acc: 1.0000\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5670 - acc: 1.0000\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5666 - acc: 1.0000\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5662 - acc: 1.0000\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5658 - acc: 1.0000\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5654 - acc: 1.0000\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5650 - acc: 1.0000\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5646 - acc: 1.0000\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5642 - acc: 1.0000\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5638 - acc: 1.0000\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5634 - acc: 1.0000\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5630 - acc: 1.0000\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5626 - acc: 1.0000\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5622 - acc: 1.0000\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5618 - acc: 1.0000\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5614 - acc: 1.0000\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5610 - acc: 1.0000\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5606 - acc: 1.0000\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5602 - acc: 1.0000\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5598 - acc: 1.0000\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5594 - acc: 1.0000\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5590 - acc: 1.0000\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5586 - acc: 1.0000\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5582 - acc: 1.0000\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5578 - acc: 1.0000\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5574 - acc: 1.0000\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5570 - acc: 1.0000\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5566 - acc: 1.0000\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5562 - acc: 1.0000\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5558 - acc: 1.0000\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5554 - acc: 1.0000\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5550 - acc: 1.0000\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5546 - acc: 1.0000\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5542 - acc: 1.0000\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5538 - acc: 1.0000\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5534 - acc: 1.0000\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5530 - acc: 1.0000\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5526 - acc: 1.0000\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5522 - acc: 1.0000\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5518 - acc: 1.0000\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5514 - acc: 1.0000\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5510 - acc: 1.0000\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5507 - acc: 1.0000\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5503 - acc: 1.0000\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5499 - acc: 1.0000\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5495 - acc: 1.0000\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5491 - acc: 1.0000\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5487 - acc: 1.0000\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5483 - acc: 1.0000\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5479 - acc: 1.0000\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5475 - acc: 1.0000\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5471 - acc: 1.0000\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5467 - acc: 1.0000\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5464 - acc: 1.0000\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5460 - acc: 1.0000\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5456 - acc: 1.0000\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5452 - acc: 1.0000\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5448 - acc: 1.0000\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5444 - acc: 1.0000\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5440 - acc: 1.0000\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5436 - acc: 1.0000\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5433 - acc: 1.0000\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5429 - acc: 1.0000\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5425 - acc: 1.0000\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5421 - acc: 1.0000\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5417 - acc: 1.0000\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5413 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5409 - acc: 1.0000\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5406 - acc: 1.0000\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5402 - acc: 1.0000\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5398 - acc: 1.0000\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5394 - acc: 1.0000\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5390 - acc: 1.0000\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5386 - acc: 1.0000\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5383 - acc: 1.0000\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5379 - acc: 1.0000\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5375 - acc: 1.0000\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5371 - acc: 1.0000\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5367 - acc: 1.0000\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5364 - acc: 1.0000\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5360 - acc: 1.0000\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5356 - acc: 1.0000\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5352 - acc: 1.0000\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5348 - acc: 1.0000\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5345 - acc: 1.0000\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5341 - acc: 1.0000\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5337 - acc: 1.0000\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5333 - acc: 1.0000\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5329 - acc: 1.0000\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5326 - acc: 1.0000\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5322 - acc: 1.0000\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5318 - acc: 1.0000\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5314 - acc: 1.0000\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5311 - acc: 1.0000\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5307 - acc: 1.0000\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5303 - acc: 1.0000\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5299 - acc: 1.0000\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5296 - acc: 1.0000\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5292 - acc: 1.0000\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5288 - acc: 1.0000\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5284 - acc: 1.0000\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5281 - acc: 1.0000\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5277 - acc: 1.0000\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5273 - acc: 1.0000\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5269 - acc: 1.0000\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5266 - acc: 1.0000\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5262 - acc: 1.0000\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5258 - acc: 1.0000\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5254 - acc: 1.0000\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5251 - acc: 1.0000\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5247 - acc: 1.0000\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5243 - acc: 1.0000\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5240 - acc: 1.0000\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5236 - acc: 1.0000\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5232 - acc: 1.0000\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5228 - acc: 1.0000\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5225 - acc: 1.0000\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5221 - acc: 1.0000\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5217 - acc: 1.0000\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5214 - acc: 1.0000\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5210 - acc: 1.0000\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5206 - acc: 1.0000\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5203 - acc: 1.0000\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5199 - acc: 1.0000\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5195 - acc: 1.0000\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5192 - acc: 1.0000\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5188 - acc: 1.0000\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5184 - acc: 1.0000\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5181 - acc: 1.0000\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5177 - acc: 1.0000\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5173 - acc: 1.0000\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5170 - acc: 1.0000\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5166 - acc: 1.0000\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5162 - acc: 1.0000\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5159 - acc: 1.0000\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5155 - acc: 1.0000\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5151 - acc: 1.0000\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5148 - acc: 1.0000\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5144 - acc: 1.0000\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5140 - acc: 1.0000\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5137 - acc: 1.0000\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5133 - acc: 1.0000\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5130 - acc: 1.0000\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5126 - acc: 1.0000\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5122 - acc: 1.0000\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5119 - acc: 1.0000\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5115 - acc: 1.0000\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5112 - acc: 1.0000\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5108 - acc: 1.0000\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5104 - acc: 1.0000\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5101 - acc: 1.0000\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5097 - acc: 1.0000\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5094 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5090 - acc: 1.0000\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5086 - acc: 1.0000\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5083 - acc: 1.0000\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5079 - acc: 1.0000\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5076 - acc: 1.0000\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5072 - acc: 1.0000\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5068 - acc: 1.0000\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5065 - acc: 1.0000\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5061 - acc: 1.0000\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5058 - acc: 1.0000\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5054 - acc: 1.0000\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5051 - acc: 1.0000\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5047 - acc: 1.0000\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5044 - acc: 1.0000\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5040 - acc: 1.0000\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5036 - acc: 1.0000\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5033 - acc: 1.0000\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5029 - acc: 1.0000\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5026 - acc: 1.0000\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5022 - acc: 1.0000\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5019 - acc: 1.0000\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5015 - acc: 1.0000\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5012 - acc: 1.0000\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5008 - acc: 1.0000\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5005 - acc: 1.0000\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5001 - acc: 1.0000\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4998 - acc: 1.0000\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4994 - acc: 1.0000\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4991 - acc: 1.0000\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4987 - acc: 1.0000\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4984 - acc: 1.0000\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4980 - acc: 1.0000\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4977 - acc: 1.0000\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4973 - acc: 1.0000\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4970 - acc: 1.0000\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4966 - acc: 1.0000\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4963 - acc: 1.0000\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4959 - acc: 1.0000\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4956 - acc: 1.0000\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4952 - acc: 1.0000\n",
      "Epoch 472/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-84a5b13decff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list=[]\n",
    "N=0\n",
    "for x in range(y_1.shape[0]):\n",
    "    if (y_2[x] - y_1[x] > 0):\n",
    "        list.append(1)\n",
    "    else:\n",
    "        list.append(0)\n",
    "y__=np.array(list)\n",
    "y_=np.reshape(y__,(126,1))\n",
    "y=y_[N]\n",
    "X=np.array(KS11)[:20]\n",
    "X=np.reshape(X,(1,20,6))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(3))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(X, y, epochs=1000)\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "model.predict(X)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from keras.models import Model\n",
    " from keras.layers import Input, Dense, LSTM\n",
    " import numpy as np\n",
    "\n",
    "\n",
    " x = np.array([[[1.], [2.], [3.], [4.], [5.]]])\n",
    " y = np.array([[6.],[2]])\n",
    "y.shape\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (2, 5, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (2, 3)                    60        \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (2, 1)                    4         \n",
      "=================================================================\n",
      "Total params: 64\n",
      "Trainable params: 64\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 1 input samples and 2 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-1ef1bf0c91cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# Check that all arrays have the same length.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck_array_lengths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m                 \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_array_length_consistency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m                 \u001b[1;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[1;34m(inputs, targets, weights)\u001b[0m\n\u001b[0;32m    242\u001b[0m                          \u001b[1;34m'the same number of samples as target arrays. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                          \u001b[1;34m'Found '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' input samples '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[0;32m    245\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         raise ValueError('All sample_weight arrays should have '\n",
      "\u001b[1;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 1 input samples and 2 target samples."
     ]
    }
   ],
   "source": [
    "\n",
    " xInput = Input(batch_shape=(1, 5, 1))\n",
    " xLstm = LSTM(3)(xInput)\n",
    " xOutput = Dense(1)(xLstm)\n",
    "\n",
    "\n",
    " model = Model(xInput, xOutput)\n",
    " model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    " print(model.summary())\n",
    "\n",
    "\n",
    " model.fit(x, y, epochs=50, batch_size=1, verbose=1)\n",
    " model.predict(x, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " x = np.array([1,2,3,4,5])\n",
    " y = np.array([6])\n",
    " x = np.reshape(x, (1, 5, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/3000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 76.6222\n",
      "Epoch 2/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 76.2672\n",
      "Epoch 3/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 75.8803\n",
      "Epoch 4/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 75.4501\n",
      "Epoch 5/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 74.9565\n",
      "Epoch 6/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 74.4101\n",
      "Epoch 7/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 73.8435\n",
      "Epoch 8/3000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 73.1870\n",
      "Epoch 9/3000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 72.5742\n",
      "Epoch 10/3000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 71.8946\n",
      "Epoch 11/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 71.1105\n",
      "Epoch 12/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 70.4595\n",
      "Epoch 13/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 69.7123\n",
      "Epoch 14/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 69.0538\n",
      "Epoch 15/3000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 68.4490\n",
      "Epoch 16/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 67.7724\n",
      "Epoch 17/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 67.2151\n",
      "Epoch 18/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 66.5753\n",
      "Epoch 19/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 66.0127\n",
      "Epoch 20/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 65.5173\n",
      "Epoch 21/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 64.9200\n",
      "Epoch 22/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 64.3760\n",
      "Epoch 23/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 63.8582\n",
      "Epoch 24/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 63.3417\n",
      "Epoch 25/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 62.8205\n",
      "Epoch 26/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 62.3256\n",
      "Epoch 27/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 61.8365\n",
      "Epoch 28/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 61.3607\n",
      "Epoch 29/3000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.8477\n",
      "Epoch 30/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 60.3855\n",
      "Epoch 31/3000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 59.8972\n",
      "Epoch 32/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 59.4687\n",
      "Epoch 33/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 58.9817\n",
      "Epoch 34/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 58.5159\n",
      "Epoch 35/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 58.0821\n",
      "Epoch 36/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 57.6252\n",
      "Epoch 37/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 57.1738\n",
      "Epoch 38/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 56.7597\n",
      "Epoch 39/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 56.3342\n",
      "Epoch 40/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 55.8804\n",
      "Epoch 41/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 55.4617\n",
      "Epoch 42/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 55.0494\n",
      "Epoch 43/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 54.6304\n",
      "Epoch 44/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 54.2035\n",
      "Epoch 45/3000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.7907\n",
      "Epoch 46/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 53.3892\n",
      "Epoch 47/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 52.9691\n",
      "Epoch 48/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 52.5983\n",
      "Epoch 49/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 52.2037\n",
      "Epoch 50/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 51.7957\n",
      "Epoch 51/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 51.4083\n",
      "Epoch 52/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 51.0108\n",
      "Epoch 53/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 50.6309\n",
      "Epoch 54/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 50.2641\n",
      "Epoch 55/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 49.8845\n",
      "Epoch 56/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 49.4911\n",
      "Epoch 57/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 49.1273\n",
      "Epoch 58/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 48.7652\n",
      "Epoch 59/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 48.4067\n",
      "Epoch 60/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 48.0257\n",
      "Epoch 61/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 47.6735\n",
      "Epoch 62/3000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.3274\n",
      "Epoch 63/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 46.9443\n",
      "Epoch 64/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 46.6230\n",
      "Epoch 65/3000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.2606\n",
      "Epoch 66/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 45.9214\n",
      "Epoch 67/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 45.5591\n",
      "Epoch 68/3000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.2251\n",
      "Epoch 69/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 44.9019\n",
      "Epoch 70/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 44.5588\n",
      "Epoch 71/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 44.2202\n",
      "Epoch 72/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 43.9066\n",
      "Epoch 73/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 43.5620\n",
      "Epoch 74/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 43.2562\n",
      "Epoch 75/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 42.9191\n",
      "Epoch 76/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 42.5842\n",
      "Epoch 77/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 42.2899\n",
      "Epoch 78/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 41.9605\n",
      "Epoch 79/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 41.6471\n",
      "Epoch 80/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 41.3486\n",
      "Epoch 81/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 41.0257\n",
      "Epoch 82/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 40.7237\n",
      "Epoch 83/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 40.4166\n",
      "Epoch 84/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 40.1471\n",
      "Epoch 85/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 39.8063\n",
      "Epoch 86/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 39.5142\n",
      "Epoch 87/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 39.2277\n",
      "Epoch 88/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 38.9373\n",
      "Epoch 89/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 38.6783\n",
      "Epoch 90/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 38.3408\n",
      "Epoch 91/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 38.0711\n",
      "Epoch 92/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 37.7967\n",
      "Epoch 93/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 37.5219\n",
      "Epoch 94/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 37.2381\n",
      "Epoch 95/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 36.9586\n",
      "Epoch 96/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 36.6652\n",
      "Epoch 97/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 36.4012\n",
      "Epoch 98/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 36.1509\n",
      "Epoch 99/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 35.8647\n",
      "Epoch 100/3000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.6040\n",
      "Epoch 101/3000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 35.3286\n",
      "Epoch 102/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 35.0724\n",
      "Epoch 103/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 34.8195\n",
      "Epoch 104/3000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 34.5602\n",
      "Epoch 105/3000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.2961\n",
      "Epoch 106/3000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.7342"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-850a664d8ba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    " from keras.models import Model\n",
    " from keras.layers import Input, Dense, LSTM\n",
    " import numpy as np\n",
    "\n",
    "\n",
    " x = np.array([[1,2,3],[2,3,4],[3,4,5],[4,5,6],[5,6,7],[6,7,8],[7,8,9],[8,9,10],[9,10,11],[10,11,12],[11,12,13],[12,13,14]])\n",
    " y = np.array([[4],[5],[6],[7],[8],[9],[10],[11],[12],[13],[14],[15]])\n",
    " x = np.reshape(x, (12, 1, 3))\n",
    "x_train=x[:10]\n",
    "x_test=x[10:]\n",
    "y_train=y[:10]\n",
    "y_test=y[10:]\n",
    "model = Sequential()\n",
    "model.add(LSTM(3))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train,y_train, epochs=3000, batch_size=1,verbose=1)\n",
    "\n",
    " print(model.summary())\n",
    " model.predict(x_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "150/150 [==============================] - 2s 17ms/step - loss: 2838464.2183\n",
      "Epoch 2/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2837958.2833\n",
      "Epoch 3/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2837452.8467\n",
      "Epoch 4/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2836947.7717\n",
      "Epoch 5/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2836442.7800\n",
      "Epoch 6/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2835937.9550\n",
      "Epoch 7/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2835433.2000\n",
      "Epoch 8/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2834928.5950\n",
      "Epoch 9/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2834424.0933\n",
      "Epoch 10/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2833919.7450\n",
      "Epoch 11/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2833415.4467\n",
      "Epoch 12/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2832911.1183\n",
      "Epoch 13/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2832406.8533\n",
      "Epoch 14/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2831902.7167\n",
      "Epoch 15/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2831398.5867\n",
      "Epoch 16/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2830894.5800\n",
      "Epoch 17/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2830390.5067\n",
      "Epoch 18/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2829886.5133\n",
      "Epoch 19/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 2829382.6083\n",
      "Epoch 20/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2828878.8367\n",
      "Epoch 21/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2828375.0867\n",
      "Epoch 22/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2827871.3767\n",
      "Epoch 23/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2827367.7050\n",
      "Epoch 24/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2826864.1317\n",
      "Epoch 25/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2826360.5183\n",
      "Epoch 26/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2825856.9667\n",
      "Epoch 27/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2825353.4533\n",
      "Epoch 28/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2824850.0500\n",
      "Epoch 29/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2824346.6267\n",
      "Epoch 30/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2823843.2133\n",
      "Epoch 31/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2823339.9000\n",
      "Epoch 32/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2822836.6750\n",
      "Epoch 33/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2822333.4650\n",
      "Epoch 34/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2821830.3733\n",
      "Epoch 35/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2821327.2550\n",
      "Epoch 36/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2820824.1717\n",
      "Epoch 37/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2820321.1350\n",
      "Epoch 38/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2819818.2450\n",
      "Epoch 39/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2819315.3433\n",
      "Epoch 40/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2818812.5067\n",
      "Epoch 41/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2818309.6483\n",
      "Epoch 42/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2817806.9483\n",
      "Epoch 43/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2817304.2400\n",
      "Epoch 44/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2816801.6317\n",
      "Epoch 45/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2816298.8667\n",
      "Epoch 46/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2815796.3217\n",
      "Epoch 47/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2815293.7350\n",
      "Epoch 48/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2814791.1850\n",
      "Epoch 49/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2814288.7950\n",
      "Epoch 50/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2813786.3683\n",
      "Epoch 51/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2813283.9933\n",
      "Epoch 52/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2812781.6533\n",
      "Epoch 53/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2812279.3900\n",
      "Epoch 54/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2811777.2433\n",
      "Epoch 55/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2811275.0833\n",
      "Epoch 56/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2810772.8533\n",
      "Epoch 57/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2810270.7983\n",
      "Epoch 58/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2809768.7250\n",
      "Epoch 59/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2809266.6950\n",
      "Epoch 60/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2808764.7083\n",
      "Epoch 61/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2808262.7683\n",
      "Epoch 62/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2807760.8567\n",
      "Epoch 63/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2807259.0617\n",
      "Epoch 64/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2806757.2650\n",
      "Epoch 65/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2806255.5183\n",
      "Epoch 66/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2805753.7767\n",
      "Epoch 67/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2805252.1117\n",
      "Epoch 68/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2804750.5417\n",
      "Epoch 69/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2804248.9633\n",
      "Epoch 70/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 2803747.4000\n",
      "Epoch 71/500\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 2803245.9250\n",
      "Epoch 72/500\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2802744.6133\n",
      "Epoch 73/500\n",
      " 25/150 [====>.........................] - ETA: 0s - loss: 2759939.2700"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-d88acd3ada50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    " from keras.models import Model\n",
    " from keras.layers import Input, Dense, LSTM\n",
    " import numpy as np\n",
    "\n",
    "len=150\n",
    "x=KS[:200]\n",
    "y=KS[\"Close\"][:200]\n",
    "x = np.array(x)\n",
    "y=np.array(y)\n",
    "x=np.reshape(x,(200,1,6))\n",
    "x_train=x[:len]\n",
    "x_test=x[len:]\n",
    "y_train=y[:len]\n",
    "y_test=y[len:]\n",
    "model = Sequential()\n",
    "model.add(LSTM(3))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train,y_train, epochs=500, batch_size=1,verbose=1)\n",
    "\n",
    " print(model.summary())\n",
    " model.predict(x_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
